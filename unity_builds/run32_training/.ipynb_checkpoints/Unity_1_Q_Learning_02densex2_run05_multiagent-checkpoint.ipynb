{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-agents already installed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import mlagents\n",
    "    from mlagents_envs.environment import UnityEnvironment as UE\n",
    "    from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "    print(\"ml-agents already installed\")\n",
    "except ImportError:\n",
    "#     !pip install mlagents==0.26.0\n",
    "    print(\"Installed ml-agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "from math import floor\n",
    "\n",
    "\n",
    "class VisualQNetwork(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    input_shape: Tuple[int], \n",
    "    encoding_size: int, \n",
    "    output_size: int\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Creates a neural network that takes as input a batch of images (3\n",
    "    dimensional tensors) and outputs a batch of outputs (1 dimensional\n",
    "    tensors)\n",
    "    \"\"\"\n",
    "    super(VisualQNetwork, self).__init__()\n",
    "#     height = input_shape[0]\n",
    "#     width = input_shape[1]\n",
    "#     initial_channels = input_shape[2]\n",
    "#     conv_1_hw = self.conv_output_shape((height, width), 8, 4)\n",
    "#     conv_2_hw = self.conv_output_shape(conv_1_hw, 4, 2)\n",
    "#     self.final_flat = conv_2_hw[0] * conv_2_hw[1] * 32\n",
    "    \n",
    "    \n",
    "#     self.conv1 = torch.nn.Conv2d(initial_channels, 16, [8, 8], [4, 4])\n",
    "#     self.conv2 = torch.nn.Conv2d(16, 32, [4, 4], [2, 2])\n",
    "#     self.dense1 = torch.nn.Linear(self.final_flat, encoding_size)\n",
    "\n",
    "    \n",
    "    self.dense1 = torch.nn.Linear(input_shape[0], encoding_size)\n",
    "    self.dense2 = torch.nn.Linear(encoding_size, encoding_size)\n",
    "    \n",
    "    self.dense2_x1 = torch.nn.Linear(encoding_size, output_size)\n",
    "    self.dense2_x2 = torch.nn.Linear(encoding_size, output_size)\n",
    "    self.dense2_x3 = torch.nn.Linear(encoding_size, output_size)\n",
    "\n",
    "    \n",
    "    \n",
    "  def forward(self, visual_obs: torch.tensor):\n",
    "#     print(\"torch input size:\", visual_obs.size())\n",
    "#     visual_obs = visual_obs.permute(0, 3, 1, 2)\n",
    "#     conv_1 = torch.relu(self.conv1(visual_obs))\n",
    "#     conv_2 = torch.relu(self.conv2(conv_1))\n",
    "#     hidden = self.dense1(conv_2.reshape([-1, self.final_flat]))\n",
    "\n",
    "    hidden = self.dense1(visual_obs)\n",
    "    hidden = torch.relu(hidden)\n",
    "\n",
    "    hidden = self.dense2(hidden)\n",
    "    hidden = torch.relu(hidden)\n",
    "\n",
    "    x1 = self.dense2_x1(hidden)\n",
    "    x1 = torch.relu(x1)\n",
    "    x2 = self.dense2_x2(hidden)\n",
    "    x2 = torch.relu(x2)\n",
    "    x3 = self.dense2_x3(hidden)\n",
    "    x3 = torch.relu(x3)\n",
    "\n",
    "    return x1, x2, x3\n",
    "\n",
    "  @staticmethod\n",
    "  def conv_output_shape(\n",
    "    h_w: Tuple[int, int],\n",
    "    kernel_size: int = 1,\n",
    "    stride: int = 1,\n",
    "    pad: int = 0,\n",
    "    dilation: int = 1,\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Computes the height and width of the output of a convolution layer.\n",
    "    \"\"\"\n",
    "    h = floor(\n",
    "      ((h_w[0] + (2 * pad) - (dilation * (kernel_size - 1)) - 1) / stride) + 1\n",
    "    )\n",
    "    w = floor(\n",
    "      ((h_w[1] + (2 * pad) - (dilation * (kernel_size - 1)) - 1) / stride) + 1\n",
    "    )\n",
    "    return h, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import NamedTuple, List\n",
    "\n",
    "\n",
    "class Experience(NamedTuple):\n",
    "  \"\"\"\n",
    "  An experience contains the data of one Agent transition.\n",
    "  - Observation\n",
    "  - Action\n",
    "  - Reward\n",
    "  - Done flag\n",
    "  - Next Observation\n",
    "  \"\"\"\n",
    "\n",
    "  obs: np.ndarray\n",
    "  action: np.ndarray\n",
    "  reward: float\n",
    "  done: bool\n",
    "  next_obs: np.ndarray\n",
    "\n",
    "# A Trajectory is an ordered sequence of Experiences\n",
    "Trajectory = List[Experience]\n",
    "\n",
    "# A Buffer is an unordered list of Experiences from multiple Trajectories\n",
    "Buffer = List[Experience]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import ActionTuple, BaseEnv\n",
    "from typing import Dict\n",
    "import random\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "  @staticmethod\n",
    "  def generate_trajectories(\n",
    "    env: BaseEnv, q_net: VisualQNetwork, buffer_size: int, epsilon: float\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Given a Unity Environment and a Q-Network, this method will generate a\n",
    "    buffer of Experiences obtained by running the Environment with the Policy\n",
    "    derived from the Q-Network.\n",
    "    :param BaseEnv: The UnityEnvironment used.\n",
    "    :param q_net: The Q-Network used to collect the data.\n",
    "    :param buffer_size: The minimum size of the buffer this method will return.\n",
    "    :param epsilon: Will add a random normal variable with standard deviation.\n",
    "    epsilon to the value heads of the Q-Network to encourage exploration.\n",
    "    :returns: a Tuple containing the created buffer and the average cumulative\n",
    "    the Agents obtained.\n",
    "    \"\"\"\n",
    "    # Create an empty Buffer\n",
    "    buffer: Buffer = []\n",
    "\n",
    "    # Reset the environment\n",
    "    env.reset()\n",
    "    # Read and store the Behavior Name of the Environment\n",
    "    behavior_name = list(env.behavior_specs)[0]\n",
    "    # Read and store the Behavior Specs of the Environment\n",
    "    spec = env.behavior_specs[behavior_name]\n",
    "\n",
    "    # Create a Mapping from AgentId to Trajectories. This will help us create\n",
    "    # trajectories for each Agents\n",
    "    dict_trajectories_from_agent: Dict[int, Trajectory] = {}\n",
    "    # Create a Mapping from AgentId to the last observation of the Agent\n",
    "    dict_last_obs_from_agent: Dict[int, np.ndarray] = {}\n",
    "    # Create a Mapping from AgentId to the last observation of the Agent\n",
    "    dict_last_action_from_agent: Dict[int, np.ndarray] = {}\n",
    "    # Create a Mapping from AgentId to cumulative reward (Only for reporting)\n",
    "    dict_cumulative_reward_from_agent: Dict[int, float] = {}\n",
    "    # Create a list to store the cumulative rewards obtained so far\n",
    "    cumulative_rewards: List[float] = []\n",
    "    \n",
    "    \n",
    "    entered_terminal = False\n",
    "    while len(buffer) < buffer_size:  # While not enough data in the buffer\n",
    "      # Get the Decision Steps and Terminal Steps of the Agents\n",
    "      decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    \n",
    "        # For all Agents with a Terminal Step:\n",
    "      for agent_id_terminated in terminal_steps:\n",
    "#         print(\"entered agent with terminal step\")\n",
    "#         print(agent_id_terminated)\n",
    "\n",
    "        # Create its last experience (is last because the Agent terminated)\n",
    "        last_experience = Experience(\n",
    "          obs=dict_last_obs_from_agent[agent_id_terminated].copy(),\n",
    "          reward=terminal_steps[agent_id_terminated].reward,\n",
    "          done=not terminal_steps[agent_id_terminated].interrupted,\n",
    "          action=dict_last_action_from_agent[agent_id_terminated].copy(),\n",
    "          next_obs=terminal_steps[agent_id_terminated].obs[0],\n",
    "        )\n",
    "        # Clear its last observation and action (Since the trajectory is over)\n",
    "        dict_last_obs_from_agent.pop(agent_id_terminated)\n",
    "        dict_last_action_from_agent.pop(agent_id_terminated)\n",
    "        # Report the cumulative reward\n",
    "        cumulative_reward = (\n",
    "          dict_cumulative_reward_from_agent.pop(agent_id_terminated)\n",
    "          + terminal_steps[agent_id_terminated].reward\n",
    "        )\n",
    "        print(\"cumulative reward: \", cumulative_reward)\n",
    "        cumulative_rewards.append(cumulative_reward) #  - 50\n",
    "        # Add the Trajectory and the last experience to the buffer\n",
    "        buffer.extend(dict_trajectories_from_agent.pop(agent_id_terminated))\n",
    "        buffer.append(last_experience)\n",
    "        entered_terminal = True\n",
    "\n",
    "      # For all Agents with a Decision Step:\n",
    "      for agent_id_decisions in decision_steps:\n",
    "        # If the Agent does not have a Trajectory, create an empty one\n",
    "        if agent_id_decisions not in dict_trajectories_from_agent:\n",
    "          dict_trajectories_from_agent[agent_id_decisions] = []\n",
    "          dict_cumulative_reward_from_agent[agent_id_decisions] = 0\n",
    "\n",
    "        # If the Agent requesting a decision has a \"last observation\"\n",
    "        if agent_id_decisions in dict_last_obs_from_agent:\n",
    "          # Create an Experience from the last observation and the Decision Step\n",
    "          exp = Experience(\n",
    "            obs=dict_last_obs_from_agent[agent_id_decisions].copy(),\n",
    "            reward=decision_steps[agent_id_decisions].reward, #  - 0.05\n",
    "            done=False,\n",
    "            action=dict_last_action_from_agent[agent_id_decisions].copy(),\n",
    "            next_obs=decision_steps[agent_id_decisions].obs[0],\n",
    "          )\n",
    "          # Update the Trajectory of the Agent and its cumulative reward\n",
    "          dict_trajectories_from_agent[agent_id_decisions].append(exp)\n",
    "          dict_cumulative_reward_from_agent[agent_id_decisions] += (\n",
    "            decision_steps[agent_id_decisions].reward\n",
    "          )\n",
    "        # Store the observation as the new \"last observation\"\n",
    "        dict_last_obs_from_agent[agent_id_decisions] = (\n",
    "          decision_steps[agent_id_decisions].obs[0]\n",
    "        )\n",
    "\n",
    "      # Generate an action for all the Agents that requested a decision\n",
    "      # Compute the values for each action given the observation    \n",
    "      act1, act2, act3 = q_net(torch.from_numpy(decision_steps.obs[0]))\n",
    "    \n",
    "      if len(decision_steps) == 0:\n",
    "            print(\"error: no more observations ! \")\n",
    "            env.step()\n",
    "            continue\n",
    "#       if act1.size == 0:\n",
    "#             print(\"error: Action space received = 0\")\n",
    "    #         actions_values = np.zeros((3,3))\n",
    "\n",
    "#             env.step()\n",
    "#             continue\n",
    "            \n",
    "      # get actions as arrays\n",
    "      act1 = act1.detach().numpy()\n",
    "      act2 = act2.detach().numpy()\n",
    "      act3 = act3.detach().numpy()\n",
    "    \n",
    "#       print(\"action received from QNetwork: \", act1)\n",
    "#       print(\"action received from QNetwork: \", act2)\n",
    "#       print(\"action received from QNetwork: \", act3)\n",
    "      \n",
    "      # pick the best action using argmax\n",
    "      act1 = np.argmax(act1, axis=1)\n",
    "      act2 = np.argmax(act2, axis=1)\n",
    "      act3 = np.argmax(act3, axis=1)\n",
    "      act1 = np.expand_dims(act1, axis=1)\n",
    "      act2 = np.expand_dims(act2, axis=1)\n",
    "      act3 = np.expand_dims(act3, axis=1)\n",
    "      # map action index 2 to -1 for the agent to move backwards, left, and rotate left\n",
    "      act1[act1 > 1] = -1\n",
    "      act2[act2 > 1] = -1\n",
    "      act3[act3 > 1] = -1\n",
    "\n",
    "      temp = np.hstack((act1, act2, act3))\n",
    "      actions = temp\n",
    "      actions.resize((len(decision_steps), 3))\n",
    "\n",
    "\n",
    "      # Store the action that was picked, it will be put in the trajectory later\n",
    "      for agent_index, agent_id in enumerate(decision_steps.agent_id):\n",
    "        dict_last_action_from_agent[agent_id] = actions[agent_index]\n",
    "#       print(\"dict last action: \", dict_last_action_from_agent)\n",
    "\n",
    "        \n",
    "      # Set the actions in the environment\n",
    "      # Unity Environments expect ActionTuple instances.\n",
    "      action_tuple = ActionTuple()\n",
    "      action_tuple.add_discrete(actions)\n",
    "#       print(\"filtered action received from QNetwork: \", action_tuple.discrete)\n",
    "      env.set_actions(behavior_name, action_tuple)\n",
    "      # Perform a step in the simulation\n",
    "      env.step()\n",
    "    return buffer, np.mean(cumulative_rewards)\n",
    "\n",
    "  @staticmethod\n",
    "  def update_q_net(\n",
    "    q_net: VisualQNetwork, \n",
    "    optimizer: torch.optim, \n",
    "    buffer: Buffer, \n",
    "    action_size: int\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Performs an update of the Q-Network using the provided optimizer and buffer\n",
    "    \"\"\"\n",
    "    def calculate_bellman_loss(next_pred_action, pred_action, reward, done, GAMMA, batch, action_size, action):\n",
    "        # Use the Bellman equation to update the Q-Network\n",
    "        target = (\n",
    "          reward\n",
    "          + (1.0 - done)\n",
    "          * GAMMA\n",
    "          * torch.max(next_pred_action.detach(), dim=1, keepdim=True).values\n",
    "        ).double()\n",
    "#         print(\"next_act_prediction:\", next_pred_action.detach().numpy())\n",
    "        \n",
    "#         print(\"Target:\", target)\n",
    "#         print(\"Target shape:\", target.shape)\n",
    "\n",
    "#         print(\"action:\", action)\n",
    "#         print(\"action shape: \", action.shape)\n",
    "        assert(action.shape[0] == len(batch))\n",
    "        action[action < 0] = 2\n",
    "#         print(\"action after correction:\", action)\n",
    "        \n",
    "        mask = np.eye(action_size)[action]\n",
    "#         mask = torch.zeros((len(batch), action_size))  \n",
    "#         print(\"mask: \", mask)\n",
    "#         print(\"mask shape: \", mask.shape)\n",
    "#         mask.scatter_(1, action, 1)\n",
    "#         print(\"mask after scatter: \", mask)\n",
    "        mask = torch.from_numpy(mask).double()\n",
    "#         print(\"pred_action: error\", pred_action)\n",
    "#         print(type(pred_action))\n",
    "#         print(pred_action.dtype)\n",
    "#         print(type(mask))\n",
    "#         print(mask.dtype)\n",
    "        prediction = torch.sum(pred_action.double() * mask, dim=1, keepdim=True)\n",
    "#         print(\"act_prediction:\", pred_action.detach().numpy())\n",
    "#         print(\"prediction: \", prediction)\n",
    "#         print(\"prediction shaPE: \", prediction.shape)\n",
    "#         print(\"prediction type: \", type(prediction))\n",
    "#         print(\"prediction dtype: \", prediction.dtype)\n",
    "        \n",
    "        criterion = torch.nn.MSELoss()\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    BATCH_SIZE = 1000\n",
    "    NUM_EPOCH = 3\n",
    "    GAMMA = 0.9\n",
    "    batch_size = min(len(buffer), BATCH_SIZE)\n",
    "    random.shuffle(buffer)\n",
    "    # Split the buffer into batches\n",
    "    batches = [\n",
    "      buffer[batch_size * start : batch_size * (start + 1)]\n",
    "      for start in range(int(len(buffer) / batch_size))\n",
    "    ]\n",
    "    for _ in range(NUM_EPOCH):\n",
    "      for batch in batches:\n",
    "        # Create the Tensors that will be fed in the network\n",
    "        obs = torch.from_numpy(np.stack([ex.obs for ex in batch]))\n",
    "        reward = torch.from_numpy(\n",
    "          np.array([ex.reward for ex in batch], dtype=np.float32).reshape(-1, 1)\n",
    "        )\n",
    "        done = torch.from_numpy(\n",
    "          np.array([ex.done for ex in batch], dtype=np.float32).reshape(-1, 1)\n",
    "        )\n",
    "        action = torch.from_numpy(np.stack([ex.action for ex in batch]))\n",
    "        next_obs = torch.from_numpy(np.stack([ex.next_obs for ex in batch]))\n",
    "        \n",
    "        # Prerequisite: collect outputs\n",
    "        pnext_a1, pnext_a2, pnext_a3 = q_net(next_obs)\n",
    "        p_a1, p_a2, p_a3 = q_net(obs)\n",
    "        \n",
    "        # bellman equation for each loss\n",
    "        loss1 = calculate_bellman_loss(pnext_a1, p_a1, reward, done, GAMMA, batch, action_size, action[:, 0])\n",
    "        loss2 = calculate_bellman_loss(pnext_a2, p_a2, reward, done, GAMMA, batch, action_size, action[:, 1])\n",
    "        loss3 = calculate_bellman_loss(pnext_a3, p_a3, reward, done, GAMMA, batch, action_size, action[:, 2])\n",
    "        loss = loss1 + loss2 + loss3\n",
    "        \n",
    "        # Perform the backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a new Q-Network. \n",
    "qnet = VisualQNetwork((44, 1), 126, 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridWorld environment created.\n",
      "cumulative reward:  69.7380735874176\n",
      "error: no more observations ! \n",
      "cumulative reward:  71.07348728179932\n",
      "error: no more observations ! \n",
      "cumulative reward:  73.3479962348938\n",
      "error: no more observations ! \n",
      "cumulative reward:  92.71218281984329\n",
      "error: no more observations ! \n",
      "cumulative reward:  85.24634653329849\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  171.70583057403564\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  71.4998619556427\n",
      "cumulative reward:  38.51513481140137\n",
      "error: no more observations ! \n",
      "cumulative reward:  76.30427241325378\n",
      "error: no more observations ! \n",
      "Training step  1 \treward  62.10642306009928\n",
      "\n",
      "cumulative reward:  42.60251760482788\n",
      "error: no more observations ! \n",
      "cumulative reward:  78.85873603820801\n",
      "error: no more observations ! \n",
      "cumulative reward:  65.34542083740234\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  39.82156243920326\n",
      "cumulative reward:  53.08444058895111\n",
      "cumulative reward:  59.28778672218323\n",
      "error: no more observations ! \n",
      "Training step  2 \treward  50.731263250112534\n",
      "\n",
      "cumulative reward:  74.02915143966675\n",
      "error: no more observations ! \n",
      "cumulative reward:  59.18852162361145\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  197.3969750404358\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  57.80594503879547\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  83.88250076770782\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  83.49043655395508\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  51.339402467012405\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  57.66228473186493\n",
      "error: no more observations ! \n",
      "cumulative reward:  44.79877519607544\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "Training step  3 \treward  33.820353309313454\n",
      "\n",
      "cumulative reward:  66.51798093318939\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  110.18634268641472\n",
      "error: no more observations ! \n",
      "cumulative reward:  99.46542006731033\n",
      "error: no more observations ! \n",
      "Training step  4 \treward  104.82588137686253\n",
      "\n",
      "cumulative reward:  107.65706160664558\n",
      "error: no more observations ! \n",
      "cumulative reward:  106.57533502578735\n",
      "error: no more observations ! \n",
      "cumulative reward:  132.4404410123825\n",
      "error: no more observations ! \n",
      "cumulative reward:  143.20760035514832\n",
      "error: no more observations ! \n",
      "cumulative reward:  128.33088245987892\n",
      "cumulative reward:  64.6880419254303\n",
      "error: no more observations ! \n",
      "cumulative reward:  78.17015600204468\n",
      "error: no more observations ! \n",
      "cumulative reward:  129.3085504770279\n",
      "cumulative reward:  114.9199208021164\n",
      "error: no more observations ! \n",
      "cumulative reward:  80.23419523239136\n",
      "error: no more observations ! \n",
      "cumulative reward:  100.01032841205597\n",
      "error: no more observations ! \n",
      "cumulative reward:  82.45915362238884\n",
      "cumulative reward:  76.83053123950958\n",
      "error: no more observations ! \n",
      "cumulative reward:  55.92655384540558\n",
      "error: no more observations ! \n",
      "cumulative reward:  59.923328042030334\n",
      "error: no more observations ! \n",
      "Training step  5 \treward  64.2268043756485\n",
      "\n",
      "cumulative reward:  74.99839794635773\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.53393971920013\n",
      "error: no more observations ! \n",
      "cumulative reward:  74.32580924034119\n",
      "error: no more observations ! \n",
      "cumulative reward:  78.99901497364044\n",
      "error: no more observations ! \n",
      "cumulative reward:  51.343915939331055\n",
      "cumulative reward:  71.94886666536331\n",
      "error: no more observations ! \n",
      "cumulative reward:  70.38952600955963\n",
      "error: no more observations ! \n",
      "cumulative reward:  79.98983764648438\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  68.56019604206085\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  124.17311623692513\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  99.19870573282242\n",
      "cumulative reward:  51.931261628866196\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  85.75682836771011\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  13.494693040847778\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  138.9600863456726\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  110.34999579191208\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  94.73620212078094\n",
      "cumulative reward:  38.76204562187195\n",
      "cumulative reward:  0.0\n",
      "Training step  6 \treward  8.806733842690786\n",
      "\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  44.018264293670654\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  128.98202216625214\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  311.93753930926323\n",
      "cumulative reward:  334.82015854120255\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "Training step  7 \treward  14.372393285565906\n",
      "\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  168.2893019914627\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  166.5456746816635\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  122.18588399887085\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  127.59878814220428\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  185.63474416732788\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  202.06359386444092\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  121.3740177154541\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  126.59878668189049\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  120.57066082954407\n",
      "cumulative reward:  173.06693625450134\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "Training step  8 \treward  33.64285307394134\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  9 \treward  -1.0\n",
      "\n",
      "cumulative reward:  123.54485416412354\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  10 \treward  -1.0\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  65.31596350669861\n",
      "error: no more observations ! \n",
      "cumulative reward:  67.33131432533264\n",
      "error: no more observations ! \n",
      "cumulative reward:  73.97900867462158\n",
      "error: no more observations ! \n",
      "Training step  11 \treward  68.87542883555095\n",
      "\n",
      "cumulative reward:  72.96672177314758\n",
      "error: no more observations ! \n",
      "cumulative reward:  57.92138671875\n",
      "error: no more observations ! \n",
      "cumulative reward:  61.69867515563965\n",
      "error: no more observations ! \n",
      "cumulative reward:  70.79025340080261\n",
      "error: no more observations ! \n",
      "cumulative reward:  56.88442945480347\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.88190746307373\n",
      "error: no more observations ! \n",
      "cumulative reward:  53.986973345279694\n",
      "error: no more observations ! \n",
      "cumulative reward:  59.54549199342728\n",
      "cumulative reward:  70.99857664108276\n",
      "error: no more observations ! \n",
      "cumulative reward:  63.742331862449646\n",
      "error: no more observations ! \n",
      "cumulative reward:  74.87438881397247\n",
      "error: no more observations ! \n",
      "cumulative reward:  74.95809471607208\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.88822853565216\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.90081346035004\n",
      "cumulative reward:  69.16693115234375\n",
      "error: no more observations ! \n",
      "Training step  12 \treward  70.65199104944865\n",
      "\n",
      "cumulative reward:  79.7234035730362\n",
      "error: no more observations ! \n",
      "cumulative reward:  70.06153750419617\n",
      "error: no more observations ! \n",
      "cumulative reward:  64.58386421203613\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.98499345779419\n",
      "error: no more observations ! \n",
      "cumulative reward:  76.80433475971222\n",
      "error: no more observations ! \n",
      "cumulative reward:  66.9350790977478\n",
      "error: no more observations ! \n",
      "cumulative reward:  74.28075116872787\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.11067259311676\n",
      "error: no more observations ! \n",
      "cumulative reward:  31.02112489938736\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  13 \treward  -1.0\n",
      "\n",
      "cumulative reward:  67.20012485980988\n",
      "error: no more observations ! \n",
      "cumulative reward:  30.31695419549942\n",
      "error: no more observations ! \n",
      "cumulative reward:  57.370136976242065\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  231.6418172121048\n",
      "error: no more observations ! \n",
      "Training step  14 \treward  231.6418172121048\n",
      "\n",
      "cumulative reward:  220.71749311685562\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.8219929933548\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  115.0197776556015\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  166.2084839940071\n",
      "cumulative reward:  237.53845858573914\n",
      "cumulative reward:  130.23810708522797\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  141.29446983337402\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  260.485709220171\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  167.783957362175\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  26.563793659210205\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  169.71277022361755\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  196.73138630390167\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  80.86225509643555\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  190.66084298491478\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  180.34593659639359\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  61.94026470184326\n",
      "error: no more observations ! \n",
      "cumulative reward:  63.95126247406006\n",
      "cumulative reward:  67.92396545410156\n",
      "error: no more observations ! \n",
      "Training step  15 \treward  64.60516421000163\n",
      "\n",
      "cumulative reward:  55.99061542749405\n",
      "error: no more observations ! \n",
      "cumulative reward:  65.64737457036972\n",
      "cumulative reward:  61.68715363740921\n",
      "error: no more observations ! \n",
      "cumulative reward:  101.1575455069542\n",
      "cumulative reward:  66.6000611782074\n",
      "error: no more observations ! \n",
      "cumulative reward:  102.97957038879395\n",
      "error: no more observations ! \n",
      "cumulative reward:  56.20782393217087\n",
      "cumulative reward:  104.9903576374054\n",
      "error: no more observations ! \n",
      "cumulative reward:  84.77817332744598\n",
      "cumulative reward:  100.896399974823\n",
      "cumulative reward:  108.3333191871643\n",
      "cumulative reward:  88.99747216701508\n",
      "error: no more observations ! \n",
      "cumulative reward:  102.14931058883667\n",
      "error: no more observations ! \n",
      "cumulative reward:  84.47888052463531\n",
      "error: no more observations ! \n",
      "cumulative reward:  97.47176563739777\n",
      "error: no more observations ! \n",
      "cumulative reward:  85.65235596895218\n",
      "error: no more observations ! \n",
      "cumulative reward:  65.83962452411652\n",
      "error: no more observations ! \n",
      "cumulative reward:  98.47742104530334\n",
      "error: no more observations ! \n",
      "cumulative reward:  569.5359745621681\n",
      "Training step  16 \treward  569.5359745621681\n",
      "\n",
      "cumulative reward:  555.1200739741325\n",
      "cumulative reward:  571.5580725073814\n",
      "error: no more observations ! \n",
      "cumulative reward:  557.3414748907089\n",
      "error: no more observations ! \n",
      "cumulative reward:  551.9424852132797\n",
      "error: no more observations ! \n",
      "cumulative reward:  553.3007109761238\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "Training step  17 \treward  -1.0\n",
      "\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  70.20893669128418\n",
      "error: no more observations ! \n",
      "cumulative reward:  66.68916058540344\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.67020344734192\n",
      "error: no more observations ! \n",
      "Training step  18 \treward  68.52276690800984\n",
      "\n",
      "cumulative reward:  74.78015112876892\n",
      "error: no more observations ! \n",
      "cumulative reward:  71.37734413146973\n",
      "cumulative reward:  62.76223111152649\n",
      "cumulative reward:  78.17949068546295\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.9812605381012\n",
      "error: no more observations ! \n",
      "cumulative reward:  73.61779808998108\n",
      "error: no more observations ! \n",
      "cumulative reward:  64.99645161628723\n",
      "error: no more observations ! \n",
      "cumulative reward:  80.80323624610901\n",
      "cumulative reward:  74.17470979690552\n",
      "error: no more observations ! \n",
      "cumulative reward:  78.93906450271606\n",
      "cumulative reward:  54.551141023635864\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.28368937969208\n",
      "error: no more observations ! \n",
      "cumulative reward:  62.470291674137115\n",
      "cumulative reward:  66.96152365207672\n",
      "error: no more observations ! \n",
      "cumulative reward:  74.21341180801392\n",
      "error: no more observations ! \n",
      "cumulative reward:  66.28775507211685\n",
      "cumulative reward:  56.508283853530884\n",
      "cumulative reward:  69.96062183380127\n",
      "cumulative reward:  74.96053326129913\n",
      "error: no more observations ! \n",
      "cumulative reward:  79.20751881599426\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.31303232908249\n",
      "error: no more observations ! \n",
      "cumulative reward:  66.62856006622314\n",
      "error: no more observations ! \n",
      "cumulative reward:  73.59446793794632\n",
      "cumulative reward:  69.71264708042145\n",
      "error: no more observations ! \n",
      "Training step  19 \treward  69.9785583615303\n",
      "\n",
      "cumulative reward:  87.74012005329132\n",
      "error: no more observations ! \n",
      "cumulative reward:  82.07853984832764\n",
      "error: no more observations ! \n",
      "cumulative reward:  61.93747675418854\n",
      "error: no more observations ! \n",
      "cumulative reward:  76.62338757514954\n",
      "error: no more observations ! \n",
      "cumulative reward:  83.07226395606995\n",
      "error: no more observations ! \n",
      "cumulative reward:  80.32970261573792\n",
      "cumulative reward:  69.83428406715393\n",
      "cumulative reward:  64.13326287269592\n",
      "error: no more observations ! \n",
      "cumulative reward:  63.80761098861694\n",
      "error: no more observations ! \n",
      "cumulative reward:  76.81847321987152\n",
      "error: no more observations ! \n",
      "cumulative reward:  76.86724328994751\n",
      "cumulative reward:  79.43586087226868\n",
      "error: no more observations ! \n",
      "cumulative reward:  58.05038928985596\n",
      "cumulative reward:  79.42364943027496\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.08416557312012\n",
      "error: no more observations ! \n",
      "cumulative reward:  75.00102937221527\n",
      "error: no more observations ! \n",
      "cumulative reward:  61.10857701301575\n",
      "cumulative reward:  77.79359602928162\n",
      "error: no more observations ! \n",
      "cumulative reward:  71.65447521209717\n",
      "error: no more observations ! \n",
      "cumulative reward:  65.1998211145401\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.64120292663574\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.64302444458008\n",
      "error: no more observations ! \n",
      "cumulative reward:  66.39472341537476\n",
      "Training step  20 \treward  69.55965026219685\n",
      "\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  164.46405935287476\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  172.49267435073853\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  55.514501094818115\n",
      "cumulative reward:  54.628705978393555\n",
      "cumulative reward:  136.2948318719864\n",
      "cumulative reward:  154.1096732020378\n",
      "cumulative reward:  151.701198220253\n",
      "cumulative reward:  150.7583999633789\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  152.79784226417542\n",
      "cumulative reward:  150.14401745796204\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  54.528602838516235\n",
      "cumulative reward:  53.14551281929016\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  53.262317299842834\n",
      "cumulative reward:  39.529309660196304\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  133.26092439889908\n",
      "cumulative reward:  137.5823998451233\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  59.32919263839722\n",
      "cumulative reward:  53.24195063114166\n",
      "cumulative reward:  395.9003492295742\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  44.75092649459839\n",
      "cumulative reward:  176.413468003273\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  191.10905820131302\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  53.61533719301224\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  66.8658504486084\n",
      "error: no more observations ! \n",
      "cumulative reward:  40.90048694610596\n",
      "error: no more observations ! \n",
      "cumulative reward:  67.0352292060852\n",
      "error: no more observations ! \n",
      "Training step  21 \treward  58.26718886693319\n",
      "\n",
      "cumulative reward:  58.73029351234436\n",
      "cumulative reward:  70.74973845481873\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.58067977428436\n",
      "cumulative reward:  71.89282643795013\n",
      "error: no more observations ! \n",
      "cumulative reward:  73.81481838226318\n",
      "error: no more observations ! \n",
      "cumulative reward:  53.70482611656189\n",
      "cumulative reward:  61.99714505672455\n",
      "cumulative reward:  74.27942192554474\n",
      "cumulative reward:  59.78943359851837\n",
      "error: no more observations ! \n",
      "cumulative reward:  63.105485916137695\n",
      "error: no more observations ! \n",
      "cumulative reward:  76.38009119033813\n",
      "cumulative reward:  97.65330463647842\n",
      "error: no more observations ! \n",
      "cumulative reward:  89.83227503299713\n",
      "error: no more observations ! \n",
      "cumulative reward:  94.35584688186646\n",
      "cumulative reward:  58.68646830320358\n",
      "cumulative reward:  73.4014980494976\n",
      "error: no more observations ! \n",
      "cumulative reward:  51.39134228229523\n",
      "error: no more observations ! \n",
      "cumulative reward:  73.44354844093323\n",
      "error: no more observations ! \n",
      "cumulative reward:  57.32556229829788\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.09569907188416\n",
      "cumulative reward:  75.1515371799469\n",
      "error: no more observations ! \n",
      "cumulative reward:  91.76767861843109\n",
      "error: no more observations ! \n",
      "cumulative reward:  135.0568546652794\n",
      "error: no more observations ! \n",
      "Training step  22 \treward  113.41226664185524\n",
      "\n",
      "cumulative reward:  102.28173929452896\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.22560235857964\n",
      "error: no more observations ! \n",
      "cumulative reward:  114.52883505821228\n",
      "cumulative reward:  52.353577852249146\n",
      "error: no more observations ! \n",
      "cumulative reward:  118.62054431438446\n",
      "cumulative reward:  123.36095529794693\n",
      "error: no more observations ! \n",
      "cumulative reward:  127.49652189016342\n",
      "error: no more observations ! \n",
      "cumulative reward:  129.32952070236206\n",
      "error: no more observations ! \n",
      "cumulative reward:  61.504710137844086\n",
      "cumulative reward:  131.84477525949478\n",
      "error: no more observations ! \n",
      "cumulative reward:  187.83435261249542\n",
      "error: no more observations ! \n",
      "cumulative reward:  54.20547533035278\n",
      "error: no more observations ! \n",
      "cumulative reward:  203.69733828306198\n",
      "error: no more observations ! \n",
      "cumulative reward:  87.48886984586716\n",
      "error: no more observations ! \n",
      "cumulative reward:  671.7535942196846\n",
      "error: no more observations ! \n",
      "Training step  23 \treward  671.7535942196846\n",
      "\n",
      "cumulative reward:  676.2655559778214\n",
      "error: no more observations ! \n",
      "cumulative reward:  668.6646801829338\n",
      "error: no more observations ! \n",
      "cumulative reward:  654.8253892064095\n",
      "error: no more observations ! \n",
      "cumulative reward:  661.6728146672249\n",
      "error: no more observations ! \n",
      "cumulative reward:  70.23046043515205\n",
      "error: no more observations ! \n",
      "Training step  24 \treward  70.23046043515205\n",
      "\n",
      "cumulative reward:  51.948317766189575\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.13343447446823\n",
      "cumulative reward:  74.42607471346855\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  35.992707669734955\n",
      "error: no more observations ! \n",
      "cumulative reward:  71.89683306217194\n",
      "Training step  25 \treward  53.944770365953445\n",
      "\n",
      "cumulative reward:  47.434290766716\n",
      "error: no more observations ! \n",
      "cumulative reward:  48.84008181095123\n",
      "error: no more observations ! \n",
      "cumulative reward:  75.8470538854599\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.60957038402557\n",
      "cumulative reward:  44.68740200996399\n",
      "error: no more observations ! \n",
      "cumulative reward:  71.52880322933197\n",
      "error: no more observations ! \n",
      "cumulative reward:  44.09293007850647\n",
      "cumulative reward:  74.58577284216881\n",
      "cumulative reward:  76.70352426171303\n",
      "cumulative reward:  73.47541505098343\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.68443536758423\n",
      "cumulative reward:  68.10398435592651\n",
      "cumulative reward:  87.98774945735931\n",
      "error: no more observations ! \n",
      "cumulative reward:  82.82631731033325\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  26 \treward  40.913158655166626\n",
      "\n",
      "cumulative reward:  78.28987717628479\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  72.15460443496704\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.76793330907822\n",
      "error: no more observations ! \n",
      "cumulative reward:  37.049360871315\n",
      "error: no more observations ! \n",
      "Training step  27 \treward  60.65729953845342\n",
      "\n",
      "cumulative reward:  62.6098113656044\n",
      "cumulative reward:  63.85372269153595\n",
      "error: no more observations ! \n",
      "cumulative reward:  59.822821855545044\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  72.76547756791115\n",
      "cumulative reward:  30.26168230175972\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  132.91087937355042\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  28.712053656578064\n",
      "cumulative reward:  36.146602272987366\n",
      "error: no more observations ! \n",
      "cumulative reward:  46.61304843425751\n",
      "error: no more observations ! \n",
      "cumulative reward:  41.590733766555786\n",
      "error: no more observations ! \n",
      "Training step  28 \treward  41.450128157933555\n",
      "\n",
      "cumulative reward:  37.619497776031494\n",
      "cumulative reward:  39.08200526237488\n",
      "error: no more observations ! \n",
      "cumulative reward:  42.07814836502075\n",
      "error: no more observations ! \n",
      "cumulative reward:  38.65744209289551\n",
      "error: no more observations ! \n",
      "cumulative reward:  40.354266703128815\n",
      "error: no more observations ! \n",
      "cumulative reward:  41.23428797721863\n",
      "error: no more observations ! \n",
      "cumulative reward:  39.051992893218994\n",
      "cumulative reward:  42.32647693157196\n",
      "cumulative reward:  44.486364126205444\n",
      "error: no more observations ! \n",
      "cumulative reward:  35.37381839752197\n",
      "error: no more observations ! \n",
      "cumulative reward:  39.17312169075012\n",
      "cumulative reward:  50.65455496311188\n",
      "error: no more observations ! \n",
      "cumulative reward:  49.98692560195923\n",
      "error: no more observations ! \n",
      "cumulative reward:  58.1402393579483\n",
      "error: no more observations ! \n",
      "cumulative reward:  40.30125629901886\n",
      "error: no more observations ! \n",
      "cumulative reward:  40.623950481414795\n",
      "error: no more observations ! \n",
      "cumulative reward:  40.63656234741211\n",
      "error: no more observations ! \n",
      "cumulative reward:  43.45013642311096\n",
      "error: no more observations ! \n",
      "cumulative reward:  45.702589213848114\n",
      "error: no more observations ! \n",
      "cumulative reward:  73.05013865232468\n",
      "error: no more observations ! \n",
      "cumulative reward:  66.89395767450333\n",
      "error: no more observations ! \n",
      "cumulative reward:  40.4375319480896\n",
      "cumulative reward:  37.273197412490845\n",
      "cumulative reward:  43.77828335762024\n",
      "error: no more observations ! \n",
      "cumulative reward:  36.209518909454346\n",
      "cumulative reward:  38.65764856338501\n",
      "Training step  29 \treward  38.97966206073761\n",
      "\n",
      "cumulative reward:  43.29602688550949\n",
      "cumulative reward:  43.558953523635864\n",
      "error: no more observations ! \n",
      "cumulative reward:  36.51050043106079\n",
      "error: no more observations ! \n",
      "cumulative reward:  36.87237906455994\n",
      "error: no more observations ! \n",
      "cumulative reward:  43.82934671640396\n",
      "cumulative reward:  43.1081657409668\n",
      "error: no more observations ! \n",
      "cumulative reward:  37.67026603221893\n",
      "error: no more observations ! \n",
      "cumulative reward:  34.32181179523468\n",
      "error: no more observations ! \n",
      "cumulative reward:  47.89676105976105\n",
      "error: no more observations ! \n",
      "cumulative reward:  46.079466104507446\n",
      "error: no more observations ! \n",
      "cumulative reward:  45.63427126407623\n",
      "cumulative reward:  35.75096035003662\n",
      "error: no more observations ! \n",
      "cumulative reward:  43.23681366443634\n",
      "error: no more observations ! \n",
      "cumulative reward:  47.568120300769806\n",
      "error: no more observations ! \n",
      "cumulative reward:  46.39673984050751\n",
      "error: no more observations ! \n",
      "cumulative reward:  44.86572861671448\n",
      "error: no more observations ! \n",
      "cumulative reward:  44.39297604560852\n",
      "cumulative reward:  43.513344287872314\n",
      "cumulative reward:  46.52168405056\n",
      "cumulative reward:  41.83220291137695\n",
      "error: no more observations ! \n",
      "cumulative reward:  38.91349384188652\n",
      "error: no more observations ! \n",
      "cumulative reward:  56.67415851354599\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  30 \treward  -1.0\n",
      "\n",
      "cumulative reward:  101.17157077789307\n",
      "cumulative reward:  82.03376185894012\n",
      "error: no more observations ! \n",
      "cumulative reward:  206.37987565994263\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  89.39614367485046\n",
      "error: no more observations ! \n",
      "cumulative reward:  264.9351763725281\n",
      "cumulative reward:  199.47092661261559\n",
      "cumulative reward:  387.8139789402485\n",
      "cumulative reward:  29.785000920295715\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  31 \treward  14.392500460147858\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  86.39830854535103\n",
      "error: no more observations ! \n",
      "cumulative reward:  142.02222675085068\n",
      "error: no more observations ! \n",
      "Training step  32 \treward  114.21026764810085\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  67.67677330970764\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.07149064540863\n",
      "error: no more observations ! \n",
      "cumulative reward:  66.09639835357666\n",
      "error: no more observations ! \n",
      "Training step  33 \treward  67.28155410289764\n",
      "\n",
      "cumulative reward:  67.044917345047\n",
      "error: no more observations ! \n",
      "cumulative reward:  66.56923842430115\n",
      "cumulative reward:  72.6485333442688\n",
      "error: no more observations ! \n",
      "cumulative reward:  67.00860524177551\n",
      "error: no more observations ! \n",
      "cumulative reward:  77.56930881738663\n",
      "error: no more observations ! \n",
      "cumulative reward:  446.07328349351883\n",
      "cumulative reward:  537.2611103951931\n",
      "error: no more observations ! \n",
      "cumulative reward:  560.4822184443474\n",
      "error: no more observations ! \n",
      "cumulative reward:  470.69413873553276\n",
      "cumulative reward:  59.472718715667725\n",
      "cumulative reward:  74.40684926509857\n",
      "cumulative reward:  54.46591925621033\n",
      "error: no more observations ! \n",
      "Training step  34 \treward  62.78182907899221\n",
      "\n",
      "cumulative reward:  70.57677614688873\n",
      "error: no more observations ! \n",
      "cumulative reward:  61.356058955192566\n",
      "error: no more observations ! \n",
      "cumulative reward:  76.79894548654556\n",
      "cumulative reward:  49.212321281433105\n",
      "error: no more observations ! \n",
      "cumulative reward:  64.89060062170029\n",
      "error: no more observations ! \n",
      "cumulative reward:  85.93977308273315\n",
      "error: no more observations ! \n",
      "cumulative reward:  90.245421230793\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.32034087181091\n",
      "error: no more observations ! \n",
      "cumulative reward:  120.45049917697906\n",
      "error: no more observations ! \n",
      "cumulative reward:  75.52671337127686\n",
      "cumulative reward:  61.72777056694031\n",
      "error: no more observations ! \n",
      "cumulative reward:  85.03652906417847\n",
      "error: no more observations ! \n",
      "cumulative reward:  74.17393118143082\n",
      "error: no more observations ! \n",
      "cumulative reward:  192.28898870944977\n",
      "error: no more observations ! \n",
      "cumulative reward:  73.80406355857849\n",
      "cumulative reward:  80.51123678684235\n",
      "cumulative reward:  87.68316006660461\n",
      "cumulative reward:  87.5155258178711\n",
      "error: no more observations ! \n",
      "cumulative reward:  82.09769117832184\n",
      "error: no more observations ! \n",
      "Training step  35 \treward  85.76545902093251\n",
      "\n",
      "cumulative reward:  83.20973312854767\n",
      "error: no more observations ! \n",
      "cumulative reward:  81.1840968132019\n",
      "cumulative reward:  87.1471860408783\n",
      "error: no more observations ! \n",
      "cumulative reward:  132.2268750667572\n",
      "cumulative reward:  84.74492168426514\n",
      "error: no more observations ! \n",
      "cumulative reward:  82.6045470237732\n",
      "error: no more observations ! \n",
      "cumulative reward:  158.66397535800934\n",
      "error: no more observations ! \n",
      "cumulative reward:  139.895033121109\n",
      "error: no more observations ! \n",
      "cumulative reward:  137.48384806513786\n",
      "error: no more observations ! \n",
      "cumulative reward:  183.32745599746704\n",
      "error: no more observations ! \n",
      "cumulative reward:  86.2471752166748\n",
      "cumulative reward:  204.5397505760193\n",
      "cumulative reward:  80.47849416732788\n",
      "error: no more observations ! \n",
      "cumulative reward:  88.90161794424057\n",
      "error: no more observations ! \n",
      "cumulative reward:  124.52773588895798\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.41660702228546\n",
      "error: no more observations ! \n",
      "cumulative reward:  92.52625715732574\n",
      "error: no more observations ! \n",
      "cumulative reward:  93.02422720193863\n",
      "error: no more observations ! \n",
      "Training step  36 \treward  85.98903046051662\n",
      "\n",
      "cumulative reward:  76.49658155441284\n",
      "error: no more observations ! \n",
      "cumulative reward:  92.78552389144897\n",
      "cumulative reward:  95.54394721984863\n",
      "cumulative reward:  96.82298874855042\n",
      "error: no more observations ! \n",
      "cumulative reward:  79.83952358365059\n",
      "cumulative reward:  77.28070640563965\n",
      "error: no more observations ! \n",
      "cumulative reward:  107.95096802711487\n",
      "error: no more observations ! \n",
      "cumulative reward:  94.43108057975769\n",
      "cumulative reward:  86.52869963645935\n",
      "error: no more observations ! \n",
      "cumulative reward:  85.52711763978004\n",
      "error: no more observations ! \n",
      "cumulative reward:  82.31871539354324\n",
      "cumulative reward:  82.08016711473465\n",
      "error: no more observations ! \n",
      "cumulative reward:  90.83920240402222\n",
      "error: no more observations ! \n",
      "cumulative reward:  78.83212733268738\n",
      "error: no more observations ! \n",
      "cumulative reward:  129.08339405059814\n",
      "error: no more observations ! \n",
      "cumulative reward:  102.65885436534882\n",
      "error: no more observations ! \n",
      "cumulative reward:  96.74169027805328\n",
      "error: no more observations ! \n",
      "cumulative reward:  120.17997217178345\n",
      "cumulative reward:  95.53674051165581\n",
      "error: no more observations ! \n",
      "cumulative reward:  71.17998325824738\n",
      "cumulative reward:  112.25933915376663\n",
      "error: no more observations ! \n",
      "Training step  37 \treward  91.719661206007\n",
      "\n",
      "cumulative reward:  88.36702066659927\n",
      "error: no more observations ! \n",
      "cumulative reward:  105.23522114753723\n",
      "error: no more observations ! \n",
      "cumulative reward:  112.18488413095474\n",
      "error: no more observations ! \n",
      "cumulative reward:  99.40685841441154\n",
      "error: no more observations ! \n",
      "cumulative reward:  116.96441853046417\n",
      "cumulative reward:  102.10815107822418\n",
      "error: no more observations ! \n",
      "cumulative reward:  124.81495690345764\n",
      "error: no more observations ! \n",
      "cumulative reward:  172.16749519109726\n",
      "cumulative reward:  232.40530121326447\n",
      "cumulative reward:  72.65836364030838\n",
      "cumulative reward:  212.248865544796\n",
      "error: no more observations ! \n",
      "cumulative reward:  153.3545544743538\n",
      "error: no more observations ! \n",
      "cumulative reward:  162.6399528980255\n",
      "error: no more observations ! \n",
      "cumulative reward:  133.73837971687317\n",
      "error: no more observations ! \n",
      "cumulative reward:  117.53832349181175\n",
      "error: no more observations ! \n",
      "cumulative reward:  150.4336159825325\n",
      "Training step  38 \treward  133.98596973717213\n",
      "\n",
      "cumulative reward:  161.10014647245407\n",
      "error: no more observations ! \n",
      "cumulative reward:  197.55295386910439\n",
      "error: no more observations ! \n",
      "cumulative reward:  196.6193962097168\n",
      "error: no more observations ! \n",
      "cumulative reward:  233.62283462285995\n",
      "error: no more observations ! \n",
      "cumulative reward:  194.30830764770508\n",
      "error: no more observations ! \n",
      "cumulative reward:  237.08098408579826\n",
      "error: no more observations ! \n",
      "cumulative reward:  198.8553130030632\n",
      "error: no more observations ! \n",
      "cumulative reward:  205.68532687425613\n",
      "error: no more observations ! \n",
      "cumulative reward:  127.25409203767776\n",
      "error: no more observations ! \n",
      "cumulative reward:  124.14182299375534\n",
      "cumulative reward:  148.06300818920135\n",
      "error: no more observations ! \n",
      "cumulative reward:  197.12030985951424\n",
      "error: no more observations ! \n",
      "Training step  39 \treward  172.5916590243578\n",
      "\n",
      "cumulative reward:  111.71756953001022\n",
      "error: no more observations ! \n",
      "cumulative reward:  159.0409393310547\n",
      "cumulative reward:  165.99494463205338\n",
      "error: no more observations ! \n",
      "cumulative reward:  131.25798299908638\n",
      "cumulative reward:  298.5803048014641\n",
      "error: no more observations ! \n",
      "cumulative reward:  296.1592172384262\n",
      "error: no more observations ! \n",
      "cumulative reward:  317.9779352247715\n",
      "error: no more observations ! \n",
      "cumulative reward:  303.7108356952667\n",
      "error: no more observations ! \n",
      "cumulative reward:  597.4936000108719\n",
      "error: no more observations ! \n",
      "cumulative reward:  602.6739650070667\n",
      "error: no more observations ! \n",
      "Training step  40 \treward  602.6739650070667\n",
      "\n",
      "cumulative reward:  495.8360927402973\n",
      "error: no more observations ! \n",
      "cumulative reward:  663.4748378098011\n",
      "error: no more observations ! \n",
      "cumulative reward:  664.4463452100754\n",
      "error: no more observations ! \n",
      "cumulative reward:  527.8646207749844\n",
      "error: no more observations ! \n",
      "cumulative reward:  556.4342040717602\n",
      "error: no more observations ! \n",
      "cumulative reward:  182.72324073314667\n",
      "cumulative reward:  659.2429637908936\n",
      "Training step  41 \treward  420.9831022620201\n",
      "\n",
      "cumulative reward:  643.282152056694\n",
      "error: no more observations ! \n",
      "cumulative reward:  695.2637804150581\n",
      "error: no more observations ! \n",
      "cumulative reward:  690.9112685322762\n",
      "cumulative reward:  703.4339124560356\n",
      "error: no more observations ! \n",
      "cumulative reward:  703.3031278848648\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "Training step  42 \treward  -1.0\n",
      "\n",
      "cumulative reward:  54.32623538374901\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  192.41776967048645\n",
      "cumulative reward:  45.08241820335388\n",
      "error: no more observations ! \n",
      "cumulative reward:  51.805946707725525\n",
      "error: no more observations ! \n",
      "Training step  43 \treward  48.4441824555397\n",
      "\n",
      "cumulative reward:  92.73588216304779\n",
      "error: no more observations ! \n",
      "cumulative reward:  91.12536284327507\n",
      "error: no more observations ! \n",
      "cumulative reward:  225.92281728982925\n",
      "error: no more observations ! \n",
      "cumulative reward:  428.596656024456\n",
      "error: no more observations ! \n",
      "cumulative reward:  417.3470823764801\n",
      "error: no more observations ! \n",
      "cumulative reward:  46.32140839099884\n",
      "cumulative reward:  78.45790874958038\n",
      "Training step  44 \treward  62.38965857028961\n",
      "\n",
      "cumulative reward:  59.11165904998779\n",
      "cumulative reward:  49.815194725990295\n",
      "error: no more observations ! \n",
      "cumulative reward:  48.81909143924713\n",
      "cumulative reward:  81.17038369178772\n",
      "error: no more observations ! \n",
      "cumulative reward:  108.95552062988281\n",
      "error: no more observations ! \n",
      "cumulative reward:  64.31667101383209\n",
      "cumulative reward:  74.05218386650085\n",
      "error: no more observations ! \n",
      "cumulative reward:  81.5504339337349\n",
      "error: no more observations ! \n",
      "cumulative reward:  80.09781074523926\n",
      "cumulative reward:  69.13146036863327\n",
      "cumulative reward:  93.95162671804428\n",
      "cumulative reward:  90.87423139810562\n",
      "cumulative reward:  88.4883217215538\n",
      "cumulative reward:  135.55791145563126\n",
      "error: no more observations ! \n",
      "cumulative reward:  72.03183937072754\n",
      "cumulative reward:  61.39427840709686\n",
      "error: no more observations ! \n",
      "Training step  45 \treward  89.66134307781856\n",
      "\n",
      "cumulative reward:  147.06393098831177\n",
      "cumulative reward:  151.66846787929535\n",
      "cumulative reward:  138.79083228111267\n",
      "cumulative reward:  118.0554050207138\n",
      "cumulative reward:  63.18621468544006\n",
      "error: no more observations ! \n",
      "cumulative reward:  110.62690484523773\n",
      "cumulative reward:  67.42319649457932\n",
      "cumulative reward:  108.12856757640839\n",
      "cumulative reward:  100.54476231336594\n",
      "error: no more observations ! \n",
      "cumulative reward:  96.65184083580971\n",
      "error: no more observations ! \n",
      "cumulative reward:  693.6710025072098\n",
      "error: no more observations ! \n",
      "Training step  46 \treward  693.6710025072098\n",
      "\n",
      "cumulative reward:  552.064924955368\n",
      "cumulative reward:  692.1744105219841\n",
      "error: no more observations ! \n",
      "cumulative reward:  572.6041124463081\n",
      "error: no more observations ! \n",
      "cumulative reward:  684.3026871681213\n",
      "error: no more observations ! \n",
      "cumulative reward:  696.8205823898315\n",
      "error: no more observations ! \n",
      "cumulative reward:  625.6613956689835\n",
      "error: no more observations ! \n",
      "cumulative reward:  679.6067783236504\n",
      "error: no more observations ! \n",
      "Training step  47 \treward  679.6067783236504\n",
      "\n",
      "cumulative reward:  675.9275949001312\n",
      "error: no more observations ! \n",
      "cumulative reward:  597.0050911307335\n",
      "cumulative reward:  656.6492529511452\n",
      "error: no more observations ! \n",
      "cumulative reward:  677.5197176933289\n",
      "cumulative reward:  684.4442446827888\n",
      "cumulative reward:  648.2969944775105\n",
      "error: no more observations ! \n",
      "Training step  48 \treward  648.2969944775105\n",
      "\n",
      "cumulative reward:  623.4603599011898\n",
      "error: no more observations ! \n",
      "cumulative reward:  615.8149548470974\n",
      "cumulative reward:  712.8146302700043\n",
      "error: no more observations ! \n",
      "cumulative reward:  697.3314942121506\n",
      "error: no more observations ! \n",
      "cumulative reward:  502.1809940934181\n",
      "error: no more observations ! \n",
      "Training step  49 \treward  502.1809940934181\n",
      "\n",
      "cumulative reward:  675.0586628317833\n",
      "cumulative reward:  672.184925198555\n",
      "error: no more observations ! \n",
      "cumulative reward:  672.2374333143234\n",
      "cumulative reward:  682.3921283483505\n",
      "error: no more observations ! \n",
      "cumulative reward:  662.5270066857338\n",
      "error: no more observations ! \n",
      "cumulative reward:  686.5879725813866\n",
      "error: no more observations ! \n",
      "cumulative reward:  600.4546596705914\n",
      "error: no more observations ! \n",
      "Training step  50 \treward  600.4546596705914\n",
      "\n",
      "cumulative reward:  611.9068899154663\n",
      "error: no more observations ! \n",
      "cumulative reward:  595.8382055163383\n",
      "error: no more observations ! \n",
      "cumulative reward:  683.7860633730888\n",
      "error: no more observations ! \n",
      "cumulative reward:  706.0202768445015\n",
      "error: no more observations ! \n",
      "Training step  51 \treward  706.0202768445015\n",
      "\n",
      "cumulative reward:  715.6056807041168\n",
      "error: no more observations ! \n",
      "cumulative reward:  709.5912218093872\n",
      "cumulative reward:  696.8644233942032\n",
      "error: no more observations ! \n",
      "cumulative reward:  703.1907527446747\n",
      "error: no more observations ! \n",
      "cumulative reward:  700.7709051370621\n",
      "error: no more observations ! \n",
      "cumulative reward:  683.8941260576248\n",
      "cumulative reward:  709.6459469795227\n",
      "error: no more observations ! \n",
      "Training step  52 \treward  709.6459469795227\n",
      "\n",
      "cumulative reward:  709.7626758813858\n",
      "error: no more observations ! \n",
      "cumulative reward:  714.5937685966492\n",
      "cumulative reward:  693.8803071975708\n",
      "error: no more observations ! \n",
      "cumulative reward:  701.0267188549042\n",
      "error: no more observations ! \n",
      "cumulative reward:  703.5514559745789\n",
      "error: no more observations ! \n",
      "cumulative reward:  700.2575355768204\n",
      "error: no more observations ! \n",
      "cumulative reward:  718.2421555519104\n",
      "error: no more observations ! \n",
      "Training step  53 \treward  718.2421555519104\n",
      "\n",
      "cumulative reward:  718.0815935134888\n",
      "error: no more observations ! \n",
      "cumulative reward:  711.8405707478523\n",
      "cumulative reward:  708.4054782390594\n",
      "cumulative reward:  719.6880499124527\n",
      "cumulative reward:  717.7849019765854\n",
      "cumulative reward:  715.5443478822708\n",
      "error: no more observations ! \n",
      "cumulative reward:  693.4537508487701\n",
      "error: no more observations ! \n",
      "Training step  54 \treward  693.4537508487701\n",
      "\n",
      "cumulative reward:  694.6353359222412\n",
      "error: no more observations ! \n",
      "cumulative reward:  713.7622106075287\n",
      "error: no more observations ! \n",
      "cumulative reward:  712.1406955718994\n",
      "error: no more observations ! \n",
      "cumulative reward:  709.324957549572\n",
      "error: no more observations ! \n",
      "cumulative reward:  695.1252871751785\n",
      "error: no more observations ! \n",
      "cumulative reward:  714.7715994119644\n",
      "cumulative reward:  702.9822299480438\n",
      "error: no more observations ! \n",
      "cumulative reward:  700.0235476493835\n",
      "error: no more observations ! \n",
      "Training step  55 \treward  700.0235476493835\n",
      "\n",
      "cumulative reward:  711.1848333477974\n",
      "error: no more observations ! \n",
      "cumulative reward:  703.5830037593842\n",
      "error: no more observations ! \n",
      "cumulative reward:  709.2018817663193\n",
      "error: no more observations ! \n",
      "cumulative reward:  713.675664126873\n",
      "error: no more observations ! \n",
      "cumulative reward:  707.6073797941208\n",
      "cumulative reward:  709.1255593299866\n",
      "error: no more observations ! \n",
      "cumulative reward:  720.7459383010864\n",
      "error: no more observations ! \n",
      "Training step  56 \treward  720.7459383010864\n",
      "\n",
      "cumulative reward:  723.0660424232483\n",
      "error: no more observations ! \n",
      "cumulative reward:  720.7558193206787\n",
      "error: no more observations ! \n",
      "cumulative reward:  720.2805502414703\n",
      "error: no more observations ! \n",
      "cumulative reward:  721.8270058631897\n",
      "cumulative reward:  721.9609930515289\n",
      "error: no more observations ! \n",
      "cumulative reward:  719.7466223239899\n",
      "cumulative reward:  717.829841375351\n",
      "cumulative reward:  719.6354932785034\n",
      "error: no more observations ! \n",
      "Training step  57 \treward  718.7326673269272\n",
      "\n",
      "cumulative reward:  718.6262085437775\n",
      "cumulative reward:  717.2354443073273\n",
      "cumulative reward:  719.7728976607323\n",
      "error: no more observations ! \n",
      "cumulative reward:  695.4286804199219\n",
      "error: no more observations ! \n",
      "cumulative reward:  721.8340141177177\n",
      "cumulative reward:  720.1370513439178\n",
      "error: no more observations ! \n",
      "cumulative reward:  721.019003868103\n",
      "Training step  58 \treward  721.019003868103\n",
      "\n",
      "cumulative reward:  706.6789000034332\n",
      "error: no more observations ! \n",
      "cumulative reward:  704.5958124399185\n",
      "error: no more observations ! \n",
      "cumulative reward:  719.5014088153839\n",
      "error: no more observations ! \n",
      "cumulative reward:  696.5261424779892\n",
      "cumulative reward:  689.3714802861214\n",
      "error: no more observations ! \n",
      "cumulative reward:  693.7526609897614\n",
      "cumulative reward:  702.5772691369057\n",
      "error: no more observations ! \n",
      "Training step  59 \treward  702.5772691369057\n",
      "\n",
      "cumulative reward:  708.812787592411\n",
      "error: no more observations ! \n",
      "cumulative reward:  700.72255641222\n",
      "error: no more observations ! \n",
      "cumulative reward:  704.0327383875847\n",
      "error: no more observations ! \n",
      "cumulative reward:  682.6672468185425\n",
      "error: no more observations ! \n",
      "cumulative reward:  701.7515563964844\n",
      "error: no more observations ! \n",
      "cumulative reward:  701.8204251527786\n",
      "error: no more observations ! \n",
      "cumulative reward:  719.9874823093414\n",
      "error: no more observations ! \n",
      "Training step  60 \treward  719.9874823093414\n",
      "\n",
      "cumulative reward:  721.5817077755928\n",
      "error: no more observations ! \n",
      "cumulative reward:  706.1695966124535\n",
      "error: no more observations ! \n",
      "cumulative reward:  714.9192643165588\n",
      "cumulative reward:  720.7188096046448\n",
      "error: no more observations ! \n",
      "cumulative reward:  721.8994055986404\n",
      "error: no more observations ! \n",
      "cumulative reward:  711.3929678201675\n",
      "error: no more observations ! \n",
      "cumulative reward:  725.2191224694252\n",
      "error: no more observations ! \n",
      "Training step  61 \treward  725.2191224694252\n",
      "\n",
      "cumulative reward:  702.5187704563141\n",
      "error: no more observations ! \n",
      "cumulative reward:  706.8449928760529\n",
      "cumulative reward:  720.3934820890427\n",
      "cumulative reward:  696.0803196430206\n",
      "cumulative reward:  694.0792307853699\n",
      "cumulative reward:  709.241513133049\n",
      "error: no more observations ! \n",
      "cumulative reward:  716.5783655047417\n",
      "error: no more observations ! \n",
      "Training step  62 \treward  716.5783655047417\n",
      "\n",
      "cumulative reward:  673.1323538422585\n",
      "error: no more observations ! \n",
      "cumulative reward:  716.6403353214264\n",
      "error: no more observations ! \n",
      "cumulative reward:  718.529112637043\n",
      "cumulative reward:  715.7597413063049\n",
      "error: no more observations ! \n",
      "cumulative reward:  709.9264058470726\n",
      "error: no more observations ! \n",
      "cumulative reward:  717.5266730189323\n",
      "error: no more observations ! \n",
      "Training step  63 \treward  717.5266730189323\n",
      "\n",
      "cumulative reward:  710.9494749903679\n",
      "error: no more observations ! \n",
      "cumulative reward:  712.3015654683113\n",
      "error: no more observations ! \n",
      "cumulative reward:  716.4688215255737\n",
      "cumulative reward:  708.9202254414558\n",
      "error: no more observations ! \n",
      "cumulative reward:  710.3023542165756\n",
      "error: no more observations ! \n",
      "cumulative reward:  699.2423247098923\n",
      "error: no more observations ! \n",
      "Training step  64 \treward  699.2423247098923\n",
      "\n",
      "cumulative reward:  724.1063531637192\n",
      "error: no more observations ! \n",
      "cumulative reward:  722.7463629245758\n",
      "error: no more observations ! \n",
      "cumulative reward:  702.1387429237366\n",
      "error: no more observations ! \n",
      "cumulative reward:  723.486775636673\n",
      "cumulative reward:  723.0137773752213\n",
      "error: no more observations ! \n",
      "cumulative reward:  703.8133366703987\n",
      "cumulative reward:  724.0380084514618\n",
      "error: no more observations ! \n",
      "Training step  65 \treward  724.0380084514618\n",
      "\n",
      "cumulative reward:  700.345335483551\n",
      "error: no more observations ! \n",
      "cumulative reward:  690.2838358879089\n",
      "error: no more observations ! \n",
      "cumulative reward:  724.3225526809692\n",
      "cumulative reward:  705.9646396636963\n",
      "cumulative reward:  692.7473462820053\n",
      "cumulative reward:  695.5776897668839\n",
      "error: no more observations ! \n",
      "cumulative reward:  722.3216073513031\n",
      "error: no more observations ! \n",
      "Training step  66 \treward  722.3216073513031\n",
      "\n",
      "cumulative reward:  723.6341364383698\n",
      "cumulative reward:  723.6715924739838\n",
      "error: no more observations ! \n",
      "cumulative reward:  728.4785208702087\n",
      "error: no more observations ! \n",
      "cumulative reward:  703.7848899960518\n",
      "error: no more observations ! \n",
      "cumulative reward:  705.6435762643814\n",
      "error: no more observations ! \n",
      "cumulative reward:  709.6166705489159\n",
      "error: no more observations ! \n",
      "cumulative reward:  727.1216588020325\n",
      "Training step  67 \treward  727.1216588020325\n",
      "\n",
      "cumulative reward:  725.600300192833\n",
      "cumulative reward:  725.919540643692\n",
      "error: no more observations ! \n",
      "cumulative reward:  724.7796769142151\n",
      "error: no more observations ! \n",
      "cumulative reward:  719.1238024234772\n",
      "error: no more observations ! \n",
      "cumulative reward:  723.953771352768\n",
      "error: no more observations ! \n",
      "cumulative reward:  725.3242983818054\n",
      "cumulative reward:  726.963641345501\n",
      "error: no more observations ! \n",
      "Training step  68 \treward  726.963641345501\n",
      "\n",
      "cumulative reward:  728.1716432571411\n",
      "error: no more observations ! \n",
      "cumulative reward:  726.5197237730026\n",
      "cumulative reward:  726.8313896656036\n",
      "error: no more observations ! \n",
      "cumulative reward:  728.063079893589\n",
      "error: no more observations ! \n",
      "cumulative reward:  725.254381775856\n",
      "error: no more observations ! \n",
      "cumulative reward:  725.1435995101929\n",
      "error: no more observations ! \n",
      "cumulative reward:  680.0932863950729\n",
      "error: no more observations ! \n",
      "Training step  69 \treward  680.0932863950729\n",
      "\n",
      "cumulative reward:  726.8779802322388\n",
      "error: no more observations ! \n",
      "cumulative reward:  725.3743395805359\n",
      "error: no more observations ! \n",
      "cumulative reward:  722.8968870639801\n",
      "error: no more observations ! \n",
      "cumulative reward:  721.9318952560425\n",
      "error: no more observations ! \n",
      "cumulative reward:  707.4401152729988\n",
      "error: no more observations ! \n",
      "cumulative reward:  723.823793053627\n",
      "error: no more observations ! \n",
      "cumulative reward:  725.6125569343567\n",
      "error: no more observations ! \n",
      "Training step  70 \treward  725.6125569343567\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efd524cad90>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------\n",
    "# This code is used to close an env that might not have been closed before\n",
    "try:\n",
    "  env.close()\n",
    "except:\n",
    "  pass\n",
    "# -----------------\n",
    "\n",
    "from mlagents_envs.registry import default_registry\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create the GridWorld Environment from the registry\n",
    "env = UE(file_name='run32_training', seed=1, side_channels=[])\n",
    "# env = default_registry[\"GridWorld\"].make()\n",
    "print(\"GridWorld environment created.\")\n",
    "\n",
    "# moved Qnet outside to reuse it\n",
    "\n",
    "experiences: Buffer = []\n",
    "optim = torch.optim.Adam(qnet.parameters(), lr= 0.001)\n",
    "\n",
    "cumulative_rewards: List[float] = []\n",
    "\n",
    "# The number of training steps that will be performed\n",
    "NUM_TRAINING_STEPS = 70\n",
    "# The number of experiences to collect per training step\n",
    "NUM_NEW_EXP = 1000\n",
    "# The maximum size of the Buffer\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "for n in range(NUM_TRAINING_STEPS):\n",
    "  new_exp,_ = Trainer.generate_trajectories(env, qnet, NUM_NEW_EXP, epsilon=0.1)\n",
    "  random.shuffle(experiences)\n",
    "  if len(experiences) > BUFFER_SIZE:\n",
    "    experiences = experiences[:BUFFER_SIZE]\n",
    "  experiences.extend(new_exp)\n",
    "  Trainer.update_q_net(qnet, optim, experiences, 3)\n",
    "  _, rewards = Trainer.generate_trajectories(env, qnet, 100, epsilon=0)\n",
    "  cumulative_rewards.append(rewards)\n",
    "  print(\"Training step \", n+1, \"\\treward \", rewards)\n",
    "  print()\n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Show the training graph\n",
    "plt.plot(range(NUM_TRAINING_STEPS), cumulative_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed environment\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "print(\"Closed environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.2-cp37-cp37m-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     || 7.2 MB 743 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-macosx_10_9_x86_64.whl (61 kB)\n",
      "\u001b[K     || 61 kB 441 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
