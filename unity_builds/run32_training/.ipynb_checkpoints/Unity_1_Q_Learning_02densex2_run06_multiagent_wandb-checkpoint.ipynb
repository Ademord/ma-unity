{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# wandb.init(config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-agents already installed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import mlagents\n",
    "    from mlagents_envs.environment import UnityEnvironment as UE\n",
    "    from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "    print(\"ml-agents already installed\")\n",
    "except ImportError:\n",
    "#     !pip install mlagents==0.26.0\n",
    "    print(\"Installed ml-agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "from math import floor\n",
    "\n",
    "\n",
    "class VisualQNetwork(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    input_shape: Tuple[int], \n",
    "    encoding_size: int, \n",
    "    output_size: int\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Creates a neural network that takes as input a batch of images (3\n",
    "    dimensional tensors) and outputs a batch of outputs (1 dimensional\n",
    "    tensors)\n",
    "    \"\"\"\n",
    "    super(VisualQNetwork, self).__init__()\n",
    "#     height = input_shape[0]\n",
    "#     width = input_shape[1]\n",
    "#     initial_channels = input_shape[2]\n",
    "#     conv_1_hw = self.conv_output_shape((height, width), 8, 4)\n",
    "#     conv_2_hw = self.conv_output_shape(conv_1_hw, 4, 2)\n",
    "#     self.final_flat = conv_2_hw[0] * conv_2_hw[1] * 32\n",
    "    \n",
    "    \n",
    "#     self.conv1 = torch.nn.Conv2d(initial_channels, 16, [8, 8], [4, 4])\n",
    "#     self.conv2 = torch.nn.Conv2d(16, 32, [4, 4], [2, 2])\n",
    "#     self.dense1 = torch.nn.Linear(self.final_flat, encoding_size)\n",
    "\n",
    "    \n",
    "    self.dense1 = torch.nn.Linear(input_shape[0], encoding_size)\n",
    "    self.dense2 = torch.nn.Linear(encoding_size, encoding_size)\n",
    "    \n",
    "    self.dense2_x1 = torch.nn.Linear(encoding_size, output_size)\n",
    "    self.dense2_x2 = torch.nn.Linear(encoding_size, output_size)\n",
    "    self.dense2_x3 = torch.nn.Linear(encoding_size, output_size)\n",
    "   \n",
    "    self.act = torch.nn.ReLU()\n",
    "\n",
    "    \n",
    "    \n",
    "  def forward(self, visual_obs: torch.tensor):\n",
    "#     print(\"torch input size:\", visual_obs.size())\n",
    "#     visual_obs = visual_obs.permute(0, 3, 1, 2)\n",
    "#     conv_1 = torch.relu(self.conv1(visual_obs))\n",
    "#     conv_2 = torch.relu(self.conv2(conv_1))\n",
    "#     hidden = self.dense1(conv_2.reshape([-1, self.final_flat]))\n",
    "\n",
    "    hidden = self.dense1(visual_obs)\n",
    "    hidden = self.act(hidden)\n",
    "\n",
    "    hidden = self.dense2(hidden)\n",
    "    hidden = self.act(hidden)\n",
    "\n",
    "    x1 = self.dense2_x1(hidden)\n",
    "#     x1 = torch.relu(x1)\n",
    "    x2 = self.dense2_x2(hidden)\n",
    "#     x2 = torch.relu(x2)\n",
    "    x3 = self.dense2_x3(hidden)\n",
    "#     x3 = torch.relu(x3)\n",
    "\n",
    "    return x1, x2, x3\n",
    "\n",
    "  @staticmethod\n",
    "  def conv_output_shape(\n",
    "    h_w: Tuple[int, int],\n",
    "    kernel_size: int = 1,\n",
    "    stride: int = 1,\n",
    "    pad: int = 0,\n",
    "    dilation: int = 1,\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Computes the height and width of the output of a convolution layer.\n",
    "    \"\"\"\n",
    "    h = floor(\n",
    "      ((h_w[0] + (2 * pad) - (dilation * (kernel_size - 1)) - 1) / stride) + 1\n",
    "    )\n",
    "    w = floor(\n",
    "      ((h_w[1] + (2 * pad) - (dilation * (kernel_size - 1)) - 1) / stride) + 1\n",
    "    )\n",
    "    return h, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import NamedTuple, List\n",
    "\n",
    "\n",
    "class Experience(NamedTuple):\n",
    "  \"\"\"\n",
    "  An experience contains the data of one Agent transition.\n",
    "  - Observation\n",
    "  - Action\n",
    "  - Reward\n",
    "  - Done flag\n",
    "  - Next Observation\n",
    "  \"\"\"\n",
    "\n",
    "  obs: np.ndarray\n",
    "  action: np.ndarray\n",
    "  reward: float\n",
    "  done: bool\n",
    "  next_obs: np.ndarray\n",
    "\n",
    "# A Trajectory is an ordered sequence of Experiences\n",
    "Trajectory = List[Experience]\n",
    "\n",
    "# A Buffer is an unordered list of Experiences from multiple Trajectories\n",
    "Buffer = List[Experience]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import ActionTuple, BaseEnv\n",
    "from typing import Dict\n",
    "import random\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "  @staticmethod\n",
    "  def generate_trajectories(\n",
    "    env: BaseEnv, q_net: VisualQNetwork, buffer_size: int, epsilon: float\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Given a Unity Environment and a Q-Network, this method will generate a\n",
    "    buffer of Experiences obtained by running the Environment with the Policy\n",
    "    derived from the Q-Network.\n",
    "    :param BaseEnv: The UnityEnvironment used.\n",
    "    :param q_net: The Q-Network used to collect the data.\n",
    "    :param buffer_size: The minimum size of the buffer this method will return.\n",
    "    :param epsilon: Will add a random normal variable with standard deviation.\n",
    "    epsilon to the value heads of the Q-Network to encourage exploration.\n",
    "    :returns: a Tuple containing the created buffer and the average cumulative\n",
    "    the Agents obtained.\n",
    "    \"\"\"\n",
    "    # Create an empty Buffer\n",
    "    buffer: Buffer = []\n",
    "\n",
    "    # Reset the environment\n",
    "    env.reset()\n",
    "    # Read and store the Behavior Name of the Environment\n",
    "    behavior_name = list(env.behavior_specs)[0]\n",
    "    # Read and store the Behavior Specs of the Environment\n",
    "    spec = env.behavior_specs[behavior_name]\n",
    "\n",
    "    # Create a Mapping from AgentId to Trajectories. This will help us create\n",
    "    # trajectories for each Agents\n",
    "    dict_trajectories_from_agent: Dict[int, Trajectory] = {}\n",
    "    # Create a Mapping from AgentId to the last observation of the Agent\n",
    "    dict_last_obs_from_agent: Dict[int, np.ndarray] = {}\n",
    "    # Create a Mapping from AgentId to the last observation of the Agent\n",
    "    dict_last_action_from_agent: Dict[int, np.ndarray] = {}\n",
    "    # Create a Mapping from AgentId to cumulative reward (Only for reporting)\n",
    "    dict_cumulative_reward_from_agent: Dict[int, float] = {}\n",
    "    # Create a list to store the cumulative rewards obtained so far\n",
    "    cumulative_rewards: List[float] = []\n",
    "    \n",
    "    \n",
    "    entered_terminal = False\n",
    "    while len(buffer) < buffer_size:  # While not enough data in the buffer\n",
    "      # Get the Decision Steps and Terminal Steps of the Agents\n",
    "      decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    \n",
    "        # For all Agents with a Terminal Step:\n",
    "      for agent_id_terminated in terminal_steps:\n",
    "#         print(\"entered agent with terminal step\")\n",
    "#         print(agent_id_terminated)\n",
    "\n",
    "        # Create its last experience (is last because the Agent terminated)\n",
    "        last_experience = Experience(\n",
    "          obs=dict_last_obs_from_agent[agent_id_terminated].copy(),\n",
    "          reward=terminal_steps[agent_id_terminated].reward,\n",
    "          done=not terminal_steps[agent_id_terminated].interrupted,\n",
    "          action=dict_last_action_from_agent[agent_id_terminated].copy(),\n",
    "          next_obs=terminal_steps[agent_id_terminated].obs[0],\n",
    "        )\n",
    "        # Clear its last observation and action (Since the trajectory is over)\n",
    "        dict_last_obs_from_agent.pop(agent_id_terminated)\n",
    "        dict_last_action_from_agent.pop(agent_id_terminated)\n",
    "        # Report the cumulative reward\n",
    "        cumulative_reward = (\n",
    "          dict_cumulative_reward_from_agent.pop(agent_id_terminated)\n",
    "          + terminal_steps[agent_id_terminated].reward\n",
    "        )\n",
    "        print(\"cumulative reward: \", cumulative_reward)\n",
    "        cumulative_rewards.append(cumulative_reward) #  - 50\n",
    "        # Add the Trajectory and the last experience to the buffer\n",
    "        buffer.extend(dict_trajectories_from_agent.pop(agent_id_terminated))\n",
    "        buffer.append(last_experience)\n",
    "        entered_terminal = True\n",
    "\n",
    "      # For all Agents with a Decision Step:\n",
    "      for agent_id_decisions in decision_steps:\n",
    "        # If the Agent does not have a Trajectory, create an empty one\n",
    "        if agent_id_decisions not in dict_trajectories_from_agent:\n",
    "          dict_trajectories_from_agent[agent_id_decisions] = []\n",
    "          dict_cumulative_reward_from_agent[agent_id_decisions] = 0\n",
    "\n",
    "        # If the Agent requesting a decision has a \"last observation\"\n",
    "        if agent_id_decisions in dict_last_obs_from_agent:\n",
    "          # Create an Experience from the last observation and the Decision Step\n",
    "          exp = Experience(\n",
    "            obs=dict_last_obs_from_agent[agent_id_decisions].copy(),\n",
    "            reward=decision_steps[agent_id_decisions].reward, #  - 0.05\n",
    "            done=False,\n",
    "            action=dict_last_action_from_agent[agent_id_decisions].copy(),\n",
    "            next_obs=decision_steps[agent_id_decisions].obs[0],\n",
    "          )\n",
    "          # Update the Trajectory of the Agent and its cumulative reward\n",
    "          dict_trajectories_from_agent[agent_id_decisions].append(exp)\n",
    "          dict_cumulative_reward_from_agent[agent_id_decisions] += (\n",
    "            decision_steps[agent_id_decisions].reward\n",
    "          )\n",
    "        # Store the observation as the new \"last observation\"\n",
    "        dict_last_obs_from_agent[agent_id_decisions] = (\n",
    "          decision_steps[agent_id_decisions].obs[0]\n",
    "        )\n",
    "\n",
    "      # Generate an action for all the Agents that requested a decision\n",
    "      # Compute the values for each action given the observation    \n",
    "      act1, act2, act3 = q_net(torch.from_numpy(decision_steps.obs[0]))\n",
    "    \n",
    "      if len(decision_steps) == 0:\n",
    "            print(\"error: no more observations ! \")\n",
    "            env.step()\n",
    "            continue\n",
    "#       if act1.size == 0:\n",
    "#             print(\"error: Action space received = 0\")\n",
    "#             env.step()\n",
    "#             continue\n",
    "            \n",
    "      # get actions as arrays\n",
    "      act1 = act1.detach().numpy()\n",
    "      act2 = act2.detach().numpy()\n",
    "      act3 = act3.detach().numpy()\n",
    "    \n",
    "#       print(\"action received from QNetwork: \", act1)\n",
    "#       print(\"action received from QNetwork: \", act2)\n",
    "#       print(\"action received from QNetwork: \", act3)\n",
    "      \n",
    "      # pick the best action using argmax\n",
    "      act1 = np.argmax(act1, axis=1)\n",
    "      act2 = np.argmax(act2, axis=1)\n",
    "      act3 = np.argmax(act3, axis=1)\n",
    "#       print(\"action received from argmax: \", act1)\n",
    "#       print(\"action received from argmax: \", act1.shape)\n",
    "#       act1 = np.array([act1])\n",
    "#       act2 = np.array([act2])\n",
    "#       act3 = np.array([act3])\n",
    "      act1 = np.expand_dims(act1, axis=1)\n",
    "      act2 = np.expand_dims(act2, axis=1)\n",
    "      act3 = np.expand_dims(act3, axis=1)\n",
    "#       print(\"action received from argmax expanded: \", act1)\n",
    "#       print(\"action received from argmax expanded: \", act1.shape)\n",
    "        \n",
    "      # map action index 2 to -1 for the agent to move backwards, left, and rotate left\n",
    "      act1[act1 > 1] = -1\n",
    "      act2[act2 > 1] = -1\n",
    "      act3[act3 > 1] = -1\n",
    "\n",
    "      # format to numpy arrays\n",
    "#       print(\"action received from mapping: \", act1)\n",
    "#       try:\n",
    "# #         actions_values = np.array([act1, act2, act3]).reshape(3,3)\n",
    "#         actions_values = np.vstack((act1, act2, act3))\n",
    "#       except:\n",
    "#         actions_values = np.zeros((3,3))\n",
    "#         print(\"error: network received an input of size 0 and i caught the error :/\")\n",
    "\n",
    "        #      0-8nt(type(actions_values))\n",
    "    \n",
    "    \n",
    "#       actions =  np.vstack((act1, act2, act3))\n",
    "#       actions =  np.vstack((act1, act2, act3))\n",
    "\n",
    "      temp = np.hstack((act1, act2, act3))\n",
    "#       print(\"actions stacked with hstack:\", temp)\n",
    "#       print(\"actions stacked with hstack: shape:\", temp.shape)\n",
    "#       temp = np.concatenate((act1, act2, act3), axis=1)\n",
    "#       print(\"actions stacked with concat:\", temp)\n",
    "#       print(\"actions stacked with concat: shape:\", temp.shape)\n",
    "        \n",
    "#       actions_values = np.zeros((3,3))\n",
    "#       # Add some noise with epsilon to the values\n",
    "#       actions_values += epsilon * np.random.randn(actions_values.shape[0], actions_values.shape[1]).astype(np.float32)\n",
    "#       actions = np.argmax(actions_values, axis=1)\n",
    "      \n",
    "      actions = temp\n",
    "#       print(\"final actions: \", actions)\n",
    "#       print(\"final actions shape: \", actions.shape)\n",
    "      actions.resize((len(decision_steps), 3))\n",
    "#       print(\"decision steps size:\", len(decision_steps))\n",
    "#       print(\"final actions after resize: \", actions)\n",
    "#       print(\"final actions shape: \", actions.shape)\n",
    "\n",
    "\n",
    "      # Store the action that was picked, it will be put in the trajectory later\n",
    "      for agent_index, agent_id in enumerate(decision_steps.agent_id):\n",
    "        dict_last_action_from_agent[agent_id] = actions[agent_index]\n",
    "#       print(\"dict last action: \", dict_last_action_from_agent)\n",
    "\n",
    "        \n",
    "      # Set the actions in the environment\n",
    "      # Unity Environments expect ActionTuple instances.\n",
    "      action_tuple = ActionTuple()\n",
    "      action_tuple.add_discrete(actions)\n",
    "#       print(\"filtered action received from QNetwork: \", action_tuple.discrete)\n",
    "      env.set_actions(behavior_name, action_tuple)\n",
    "      # Perform a step in the simulation\n",
    "      env.step()\n",
    "    return buffer, np.mean(cumulative_rewards)\n",
    "\n",
    "  @staticmethod\n",
    "  def update_q_net(\n",
    "    q_net: VisualQNetwork, \n",
    "    optimizer: torch.optim, \n",
    "    buffer: Buffer, \n",
    "    action_size: int\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Performs an update of the Q-Network using the provided optimizer and buffer\n",
    "    \"\"\"\n",
    "    def calculate_bellman_loss(next_pred_action, pred_action, reward, done, GAMMA, batch, action_size, action):\n",
    "        # Use the Bellman equation to update the Q-Network\n",
    "        target = (\n",
    "          reward\n",
    "          + (1.0 - done)\n",
    "          * GAMMA\n",
    "          * torch.max(next_pred_action.detach(), dim=1, keepdim=True).values\n",
    "        ).double()\n",
    "#         print(\"next_act_prediction:\", next_pred_action.detach().numpy())\n",
    "        \n",
    "#         print(\"Target:\", target)\n",
    "#         print(\"Target shape:\", target.shape)\n",
    "\n",
    "#         print(\"action:\", action)\n",
    "#         print(\"action shape: \", action.shape)\n",
    "        assert(action.shape[0] == len(batch))\n",
    "        action[action < 0] = 2\n",
    "#         print(\"action after correction:\", action)\n",
    "        \n",
    "        mask = np.eye(action_size)[action]\n",
    "#         mask = torch.zeros((len(batch), action_size))  \n",
    "#         print(\"mask: \", mask)\n",
    "#         print(\"mask shape: \", mask.shape)\n",
    "#         mask.scatter_(1, action, 1)\n",
    "#         print(\"mask after scatter: \", mask)\n",
    "        mask = torch.from_numpy(mask).double()\n",
    "#         print(\"pred_action: error\", pred_action)\n",
    "#         print(type(pred_action))\n",
    "#         print(pred_action.dtype)\n",
    "#         print(type(mask))\n",
    "#         print(mask.dtype)\n",
    "        prediction = torch.sum(pred_action.double() * mask, dim=1, keepdim=True)\n",
    "#         print(\"act_prediction:\", pred_action.detach().numpy())\n",
    "#         print(\"prediction: \", prediction)\n",
    "#         print(\"prediction shaPE: \", prediction.shape)\n",
    "#         print(\"prediction type: \", type(prediction))\n",
    "#         print(\"prediction dtype: \", prediction.dtype)\n",
    "        \n",
    "        criterion = torch.nn.MSELoss()\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    BATCH_SIZE = 1000\n",
    "    NUM_EPOCH = 3\n",
    "    GAMMA = 0.9\n",
    "    batch_size = min(len(buffer), BATCH_SIZE)\n",
    "    random.shuffle(buffer)\n",
    "    # Split the buffer into batches\n",
    "    batches = [\n",
    "      buffer[batch_size * start : batch_size * (start + 1)]\n",
    "      for start in range(int(len(buffer) / batch_size))\n",
    "    ]\n",
    "    for _ in range(NUM_EPOCH):\n",
    "      for batch in batches:\n",
    "        # Create the Tensors that will be fed in the network\n",
    "        obs = torch.from_numpy(np.stack([ex.obs for ex in batch]))\n",
    "        reward = torch.from_numpy(\n",
    "          np.array([ex.reward for ex in batch], dtype=np.float32).reshape(-1, 1)\n",
    "        )\n",
    "        done = torch.from_numpy(\n",
    "          np.array([ex.done for ex in batch], dtype=np.float32).reshape(-1, 1)\n",
    "        )\n",
    "        action = torch.from_numpy(np.stack([ex.action for ex in batch]))\n",
    "        next_obs = torch.from_numpy(np.stack([ex.next_obs for ex in batch]))\n",
    "        \n",
    "        # Prerequisite: collect outputs\n",
    "        pnext_a1, pnext_a2, pnext_a3 = q_net(next_obs)\n",
    "        p_a1, p_a2, p_a3 = q_net(obs)\n",
    "        \n",
    "        # bellman equation for each loss\n",
    "        loss1 = calculate_bellman_loss(pnext_a1, p_a1, reward, done, GAMMA, batch, action_size, action[:, 0])\n",
    "        loss2 = calculate_bellman_loss(pnext_a2, p_a2, reward, done, GAMMA, batch, action_size, action[:, 1])\n",
    "        loss3 = calculate_bellman_loss(pnext_a3, p_a3, reward, done, GAMMA, batch, action_size, action[:, 2])\n",
    "        loss = loss1 + loss2 + loss3\n",
    "        \n",
    "        # Perform the backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridWorld environment created.\n",
      "cumulative reward:  5.51955708861351\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.4062246084213257\n",
      "cumulative reward:  -0.5940185785293579\n",
      "cumulative reward:  1.6465994119644165\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.9568166136741638\n",
      "error: no more observations ! \n",
      "cumulative reward:  17.814553171396255\n",
      "cumulative reward:  -0.5988785028457642\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.289321184158325\n",
      "cumulative reward:  -0.291353315114975\n",
      "cumulative reward:  12.620251655578613\n",
      "cumulative reward:  1.6416301727294922\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.336070358753204\n",
      "error: no more observations ! \n",
      "Training step  1 \treward  5.576649717986584\n",
      "\n",
      "cumulative reward:  17.492601931095123\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.7493229508399963\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.3941473960876465\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.6884593665599823\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  70.40210539102554\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  75.33880710601807\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.895408511161804\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.5044524073600769\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.57389897108078\n",
      "error: no more observations ! \n",
      "cumulative reward:  20.414720058441162\n",
      "error: no more observations ! \n",
      "Training step  2 \treward  9.844893783330917\n",
      "\n",
      "cumulative reward:  4.126940548419952\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.44579145312309265\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.163856625556946\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  38.129370391368866\n",
      "error: no more observations ! \n",
      "cumulative reward:  102.60782271623611\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.121018350124359\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.842260301113129\n",
      "cumulative reward:  6.855766147375107\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.54132080078125\n",
      "error: no more observations ! \n",
      "Training step  3 \treward  5.340091399848461\n",
      "\n",
      "cumulative reward:  0.38876843452453613\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.5899295508861542\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.905447393655777\n",
      "error: no more observations ! \n",
      "cumulative reward:  98.99498975276947\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  10.68476527929306\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.779307395219803\n",
      "cumulative reward:  -0.320422887802124\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.4469635784626007\n",
      "error: no more observations ! \n",
      "Training step  4 \treward  5.397653341293335\n",
      "\n",
      "cumulative reward:  12.655805706977844\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.3461895287036896\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.38229450583457947\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.2811678647995\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.6716861128807068\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  37.170995742082596\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  5 \treward  -1.0\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  6 \treward  -1.0\n",
      "\n",
      "cumulative reward:  75.21159422397614\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  7 \treward  -1.0\n",
      "\n",
      "cumulative reward:  1.8088227212429047\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "Training step  8 \treward  -1.0\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.47026538848877\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.567238986492157\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.1989299356937408\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.941458374261856\n",
      "Training step  9 \treward  5.010853677988052\n",
      "\n",
      "cumulative reward:  4.262374043464661\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.18705996870994568\n",
      "error: no more observations ! \n",
      "cumulative reward:  20.757971048355103\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.754342913627625\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.209155797958374\n",
      "error: no more observations ! \n",
      "cumulative reward:  25.917498499155045\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.368766218423843\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  119.5468053817749\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.55531045794487\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.976084619760513\n",
      "error: no more observations ! \n",
      "cumulative reward:  17.869277864694595\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.6890418231487274\n",
      "error: no more observations ! \n",
      "cumulative reward:  37.09878706932068\n",
      "error: no more observations ! \n",
      "cumulative reward:  106.51430332660675\n",
      "error: no more observations ! \n",
      "Training step  10 \treward  48.43404407302538\n",
      "\n",
      "cumulative reward:  1.5756895840168\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.87497416138649\n",
      "error: no more observations ! \n",
      "cumulative reward:  28.328814804553986\n",
      "error: no more observations ! \n",
      "cumulative reward:  26.51201805472374\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  31.339032471179962\n",
      "error: no more observations ! \n",
      "cumulative reward:  31.280735850334167\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  83.2966086268425\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  37.814379811286926\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.2196106910705566\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.179860651493073\n",
      "error: no more observations ! \n",
      "cumulative reward:  4.546518862247467\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.8893065452575684\n",
      "error: no more observations ! \n",
      "Training step  11 \treward  4.458824187517166\n",
      "\n",
      "cumulative reward:  3.8256475031375885\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.6001744270324707\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  24.887852996587753\n",
      "error: no more observations ! \n",
      "cumulative reward:  41.275516510009766\n",
      "error: no more observations ! \n",
      "cumulative reward:  98.39288294315338\n",
      "cumulative reward:  8.591685026884079\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.462142765522003\n",
      "error: no more observations ! \n",
      "cumulative reward:  15.233213782310486\n",
      "cumulative reward:  6.786372900009155\n",
      "error: no more observations ! \n",
      "cumulative reward:  23.00019371509552\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.94052255153656\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.981643438339233\n",
      "error: no more observations ! \n",
      "Training step  12 \treward  14.427183151245117\n",
      "\n",
      "cumulative reward:  3.0908645689487457\n",
      "error: no more observations ! \n",
      "cumulative reward:  33.07207328081131\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  25.732013672590256\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  28.861242562532425\n",
      "error: no more observations ! \n",
      "cumulative reward:  70.86624300479889\n",
      "cumulative reward:  100.3841450214386\n",
      "error: no more observations ! \n",
      "Training step  13 \treward  85.62519401311874\n",
      "\n",
      "cumulative reward:  18.21108341217041\n",
      "cumulative reward:  72.49337810277939\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.996748924255371\n",
      "error: no more observations ! \n",
      "cumulative reward:  120.18535244464874\n",
      "cumulative reward:  119.76508378982544\n",
      "error: no more observations ! \n",
      "cumulative reward:  81.54472148418427\n",
      "error: no more observations ! \n",
      "cumulative reward:  93.44010531902313\n",
      "error: no more observations ! \n",
      "cumulative reward:  17.22065931558609\n",
      "cumulative reward:  117.12618991732597\n",
      "error: no more observations ! \n",
      "cumulative reward:  123.21463632583618\n",
      "error: no more observations ! \n",
      "cumulative reward:  113.63867712020874\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  14 \treward  -1.0\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  61.46752732992172\n",
      "cumulative reward:  23.01313006877899\n",
      "cumulative reward:  1.9491012692451477\n",
      "cumulative reward:  13.042580902576447\n",
      "cumulative reward:  88.48690336942673\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  118.772305727005\n",
      "cumulative reward:  117.14398944377899\n",
      "cumulative reward:  67.53819143772125\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  99.29219591617584\n",
      "cumulative reward:  132.77020847797394\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  65.0620545744896\n",
      "cumulative reward:  58.83214843273163\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.9235177636146545\n",
      "cumulative reward:  84.25614500045776\n",
      "cumulative reward:  114.60799908638\n",
      "cumulative reward:  81.52175736427307\n",
      "cumulative reward:  54.00840878486633\n",
      "cumulative reward:  19.621585488319397\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  3.99933123588562\n",
      "cumulative reward:  13.890726029872894\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  80.9792286157608\n",
      "cumulative reward:  61.45711225271225\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  16.204108834266663\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  10.22940731048584\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  26.854033410549164\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  50.47343337535858\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  103.33123153448105\n",
      "cumulative reward:  11.774997264146805\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.420179963111877\n",
      "cumulative reward:  16.85598424077034\n",
      "error: no more observations ! \n",
      "Training step  15 \treward  15.01705382267634\n",
      "\n",
      "cumulative reward:  6.095432877540588\n",
      "cumulative reward:  25.962285429239273\n",
      "error: no more observations ! \n",
      "cumulative reward:  21.45739182829857\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.482072979211807\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.51534765958786\n",
      "cumulative reward:  14.10856717824936\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.175754338502884\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.454537451267242\n",
      "cumulative reward:  20.095254480838776\n",
      "error: no more observations ! \n",
      "cumulative reward:  52.19681832194328\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.92479830980301\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.960021197795868\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.388645231723785\n",
      "error: no more observations ! \n",
      "cumulative reward:  15.381867706775665\n",
      "error: no more observations ! \n",
      "Training step  16 \treward  14.243511378765106\n",
      "\n",
      "cumulative reward:  19.4622141122818\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.952539533376694\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.09817498922348\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.597422659397125\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.30684736371040344\n",
      "cumulative reward:  4.087015688419342\n",
      "Training step  17 \treward  3.868941493332386\n",
      "\n",
      "cumulative reward:  2.377490073442459\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.38077324628829956\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.938724398612976\n",
      "cumulative reward:  14.2955282330513\n",
      "cumulative reward:  8.772572249174118\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.3807252943515778\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.15156003832817\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.9458157420158386\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.60120975971222\n",
      "error: no more observations ! \n",
      "cumulative reward:  17.7784483730793\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.821498900651932\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.634375721216202\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.641413122415543\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.148301154375076\n",
      "cumulative reward:  11.718771696090698\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.318002998828888\n",
      "cumulative reward:  1.256755918264389\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.44049933552742\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  53.67304930090904\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "Training step  18 \treward  1.2971178789933522\n",
      "\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  58.63267421722412\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  132.4453468322754\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  9.574717938899994\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  98.65087449550629\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.6401087939739227\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  1.3090896904468536\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.110538423061371\n",
      "cumulative reward:  5.733920991420746\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.013381212949753\n",
      "Training step  19 \treward  6.541732579469681\n",
      "\n",
      "cumulative reward:  3.8568166494369507\n",
      "cumulative reward:  5.966976493597031\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.2927330434322357\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.28734126687049866\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.585346579551697\n",
      "cumulative reward:  14.04335168004036\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.20301902294158936\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.590963065624237\n",
      "error: no more observations ! \n",
      "cumulative reward:  21.124403953552246\n",
      "cumulative reward:  8.696012496948242\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.125634461641312\n",
      "cumulative reward:  5.911840230226517\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.416897177696228\n",
      "error: no more observations ! \n",
      "cumulative reward:  27.612355649471283\n",
      "error: no more observations ! \n",
      "Training step  20 \treward  19.514626413583755\n",
      "\n",
      "cumulative reward:  10.235038816928864\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.203547894954681\n",
      "error: no more observations ! \n",
      "cumulative reward:  47.149810403585434\n",
      "error: no more observations ! \n",
      "cumulative reward:  105.65892630815506\n",
      "cumulative reward:  113.67092561721802\n",
      "error: no more observations ! \n",
      "cumulative reward:  28.944370418787003\n",
      "error: no more observations ! \n",
      "cumulative reward:  29.75249335169792\n",
      "error: no more observations ! \n",
      "cumulative reward:  24.581947565078735\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "Training step  21 \treward  -1.0\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.181028127670288\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.6135351061820984\n",
      "Training step  22 \treward  4.897281616926193\n",
      "\n",
      "cumulative reward:  52.76240289211273\n",
      "error: no more observations ! \n",
      "cumulative reward:  26.186470687389374\n",
      "cumulative reward:  77.91480043530464\n",
      "cumulative reward:  19.820018589496613\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.357994705438614\n",
      "error: no more observations ! \n",
      "cumulative reward:  38.389675348997116\n",
      "cumulative reward:  89.47487407922745\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.310459405183792\n",
      "error: no more observations ! \n",
      "cumulative reward:  99.06834250688553\n",
      "error: no more observations ! \n",
      "cumulative reward:  78.62382632493973\n",
      "error: no more observations ! \n",
      "cumulative reward:  49.66850063204765\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.967192500829697\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.637785375118256\n",
      "error: no more observations ! \n",
      "Training step  23 \treward  8.302488937973976\n",
      "\n",
      "cumulative reward:  12.139185011386871\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.023996472358704\n",
      "error: no more observations ! \n",
      "cumulative reward:  19.050505459308624\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.4229346215724945\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.926599830389023\n",
      "error: no more observations ! \n",
      "cumulative reward:  33.7742663025856\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.760810613632202\n",
      "error: no more observations ! \n",
      "cumulative reward:  49.59869468212128\n",
      "error: no more observations ! \n",
      "cumulative reward:  128.66478577256203\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.3209287226200104\n",
      "error: no more observations ! \n",
      "cumulative reward:  115.87288123369217\n",
      "error: no more observations ! \n",
      "Training step  24 \treward  58.59690497815609\n",
      "\n",
      "cumulative reward:  86.39839550852776\n",
      "error: no more observations ! \n",
      "cumulative reward:  140.98753118515015\n",
      "error: no more observations ! \n",
      "cumulative reward:  465.3972117006779\n",
      "error: no more observations ! \n",
      "cumulative reward:  192.0485678911209\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.1932889223098755\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.496472239494324\n",
      "error: no more observations ! \n",
      "Training step  25 \treward  3.3448805809020996\n",
      "\n",
      "cumulative reward:  8.975615978240967\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.4875478744506836\n",
      "cumulative reward:  7.221604824066162\n",
      "cumulative reward:  6.827675253152847\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  10.23215502500534\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  158.14314129948616\n",
      "Training step  26 \treward  158.14314129948616\n",
      "\n",
      "cumulative reward:  127.48442435264587\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.11383581161499\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.115785956382751\n",
      "cumulative reward:  146.92376628518105\n",
      "error: no more observations ! \n",
      "cumulative reward:  116.76444214582443\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  166.65420904755592\n",
      "error: no more observations ! \n",
      "cumulative reward:  223.78737917542458\n",
      "error: no more observations ! \n",
      "cumulative reward:  109.19506666064262\n",
      "error: no more observations ! \n",
      "Training step  27 \treward  109.19506666064262\n",
      "\n",
      "cumulative reward:  78.54050976037979\n",
      "error: no more observations ! \n",
      "cumulative reward:  98.8761530816555\n",
      "cumulative reward:  129.2127624452114\n",
      "cumulative reward:  65.85059440135956\n",
      "error: no more observations ! \n",
      "cumulative reward:  114.30510765314102\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.5809738039970398\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.306998610496521\n",
      "error: no more observations ! \n",
      "Training step  28 \treward  0.8630124032497406\n",
      "\n",
      "cumulative reward:  -0.6902908682823181\n",
      "error: no more observations ! \n",
      "cumulative reward:  15.097017586231232\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.33203899860382\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  61.81243622303009\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.663270473480225\n",
      "error: no more observations ! \n",
      "cumulative reward:  142.230814576149\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  108.39871707558632\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  64.23855671286583\n",
      "error: no more observations ! \n",
      "Training step  29 \treward  31.619278356432915\n",
      "\n",
      "cumulative reward:  97.44676834344864\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  7.591407299041748\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  61.12238001823425\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  29.333575010299683\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  142.80862069129944\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  90.92961350083351\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  3.1789454519748688\n",
      "error: no more observations ! \n",
      "cumulative reward:  79.14567416906357\n",
      "Training step  30 \treward  41.16230981051922\n",
      "\n",
      "cumulative reward:  11.525574177503586\n",
      "cumulative reward:  103.02137124538422\n",
      "cumulative reward:  2.458040177822113\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "Training step  31 \treward  -1.0\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  3.145849347114563\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.222638189792633\n",
      "cumulative reward:  11.969545722007751\n",
      "error: no more observations ! \n",
      "Training step  32 \treward  9.779344419638315\n",
      "\n",
      "cumulative reward:  0.31917595863342285\n",
      "cumulative reward:  2.3337283730506897\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.6926490664482117\n",
      "error: no more observations ! \n",
      "cumulative reward:  71.67702811956406\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.79272747039795\n",
      "error: no more observations ! \n",
      "cumulative reward:  104.28139397501945\n",
      "error: no more observations ! \n",
      "cumulative reward:  99.16076830029488\n",
      "cumulative reward:  10.332096725702286\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.912072956562042\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.526891827583313\n",
      "error: no more observations ! \n",
      "Training step  33 \treward  10.257020503282547\n",
      "\n",
      "cumulative reward:  30.686085402965546\n",
      "cumulative reward:  107.8084662258625\n",
      "error: no more observations ! \n",
      "cumulative reward:  79.64599961042404\n",
      "error: no more observations ! \n",
      "cumulative reward:  101.63846093416214\n",
      "error: no more observations ! \n",
      "cumulative reward:  88.4565001130104\n",
      "error: no more observations ! \n",
      "cumulative reward:  98.18760669231415\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.530309915542603\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.086567759513855\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.68547034263611\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.256630063056946\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.7014162838459\n",
      "error: no more observations ! \n",
      "Training step  34 \treward  15.88117222984632\n",
      "\n",
      "cumulative reward:  20.927905440330505\n",
      "cumulative reward:  8.441922068595886\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.6640763580799103\n",
      "error: no more observations ! \n",
      "cumulative reward:  170.80693858861923\n",
      "error: no more observations ! \n",
      "cumulative reward:  136.36388492584229\n",
      "error: no more observations ! \n",
      "cumulative reward:  52.388010531663895\n",
      "cumulative reward:  10.39473083615303\n",
      "error: no more observations ! \n",
      "cumulative reward:  156.61126255989075\n",
      "error: no more observations ! \n",
      "cumulative reward:  258.5045804977417\n",
      "cumulative reward:  -0.17870783805847168\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.13877832889557\n",
      "error: no more observations ! \n",
      "cumulative reward:  37.711937844753265\n",
      "Training step  35 \treward  17.89066944519679\n",
      "\n",
      "cumulative reward:  1.7096932232379913\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.057561516761779785\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.3540970087051392\n",
      "error: no more observations ! \n",
      "cumulative reward:  80.53037312626839\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.81270635128021\n",
      "error: no more observations ! \n",
      "cumulative reward:  110.12053710222244\n",
      "cumulative reward:  66.2986107468605\n",
      "cumulative reward:  68.30873522162437\n",
      "error: no more observations ! \n",
      "cumulative reward:  39.59742224216461\n",
      "error: no more observations ! \n",
      "cumulative reward:  81.98482167720795\n",
      "error: no more observations ! \n",
      "cumulative reward:  85.21938046813011\n",
      "cumulative reward:  82.47385174036026\n",
      "cumulative reward:  17.424552857875824\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.258861064910889\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.548245012760162\n",
      "Training step  36 \treward  13.410552978515625\n",
      "\n",
      "cumulative reward:  9.0248344540596\n",
      "cumulative reward:  0.779460996389389\n",
      "cumulative reward:  10.85988974571228\n",
      "error: no more observations ! \n",
      "cumulative reward:  15.149229168891907\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.245953142642975\n",
      "error: no more observations ! \n",
      "cumulative reward:  15.049684047698975\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.69082522392273\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.66228386759758\n",
      "cumulative reward:  9.060666501522064\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.491893023252487\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.664574414491653\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.534707814455032\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.944605588912964\n",
      "cumulative reward:  19.419668525457382\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.069752037525177\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.100617349147797\n",
      "cumulative reward:  318.7887718677521\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.83117234706879\n",
      "Training step  37 \treward  68.83117234706879\n",
      "\n",
      "cumulative reward:  16.796026170253754\n",
      "cumulative reward:  17.699091255664825\n",
      "error: no more observations ! \n",
      "cumulative reward:  171.1505452990532\n",
      "cumulative reward:  45.17580994963646\n",
      "error: no more observations ! \n",
      "cumulative reward:  235.13834476470947\n",
      "cumulative reward:  325.86834222078323\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.4972630739212036\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.200791388750076\n",
      "error: no more observations ! \n",
      "Training step  38 \treward  3.8517641574144363\n",
      "\n",
      "cumulative reward:  0.5478599369525909\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.3010956943035126\n",
      "cumulative reward:  21.26091942191124\n",
      "error: no more observations ! \n",
      "cumulative reward:  87.80764326453209\n",
      "error: no more observations ! \n",
      "cumulative reward:  708.3438522219658\n",
      "error: no more observations ! \n",
      "cumulative reward:  629.9050222039223\n",
      "error: no more observations ! \n",
      "cumulative reward:  131.22803902626038\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  426.75622540712357\n",
      "error: no more observations ! \n",
      "Training step  39 \treward  212.87811270356178\n",
      "\n",
      "cumulative reward:  0.12796232104301453\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.9716110825538635\n",
      "error: no more observations ! \n",
      "cumulative reward:  46.50551438331604\n",
      "error: no more observations ! \n",
      "cumulative reward:  242.6463472545147\n",
      "cumulative reward:  422.8271074295044\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  362.57001784443855\n",
      "error: no more observations ! \n",
      "cumulative reward:  45.509842336177826\n",
      "error: no more observations ! \n",
      "cumulative reward:  22.082636654376984\n",
      "error: no more observations ! \n",
      "Training step  40 \treward  33.796239495277405\n",
      "\n",
      "cumulative reward:  4.7725599110126495\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.951718747615814\n",
      "error: no more observations ! \n",
      "cumulative reward:  17.837497264146805\n",
      "error: no more observations ! \n",
      "cumulative reward:  32.26615846157074\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.793945670127869\n",
      "error: no more observations ! \n",
      "cumulative reward:  35.04560241103172\n",
      "error: no more observations ! \n",
      "cumulative reward:  29.45234328508377\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.56355857849121\n",
      "cumulative reward:  250.89340496063232\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.501915812492371\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  662.9195973277092\n",
      "error: no more observations ! \n",
      "Training step  41 \treward  662.9195973277092\n",
      "\n",
      "cumulative reward:  690.3319988846779\n",
      "error: no more observations ! \n",
      "cumulative reward:  741.0515447258949\n",
      "cumulative reward:  750.796043753624\n",
      "error: no more observations ! \n",
      "cumulative reward:  723.5163815021515\n",
      "cumulative reward:  81.41834875941277\n",
      "error: no more observations ! \n",
      "Training step  42 \treward  81.41834875941277\n",
      "\n",
      "cumulative reward:  23.469591349363327\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.03066927194595\n",
      "cumulative reward:  331.4778964519501\n",
      "cumulative reward:  427.0003736615181\n",
      "error: no more observations ! \n",
      "cumulative reward:  49.59759086370468\n",
      "error: no more observations ! \n",
      "cumulative reward:  749.7245702147484\n",
      "cumulative reward:  749.0237433314323\n",
      "error: no more observations ! \n",
      "cumulative reward:  196.17720305919647\n",
      "error: no more observations ! \n",
      "cumulative reward:  600.3139809966087\n",
      "error: no more observations ! \n",
      "Training step  43 \treward  398.2455920279026\n",
      "\n",
      "cumulative reward:  3.9254819750785828\n",
      "cumulative reward:  197.68808841705322\n",
      "cumulative reward:  197.68356680870056\n",
      "cumulative reward:  555.717133462429\n",
      "error: no more observations ! \n",
      "cumulative reward:  549.3512764573097\n",
      "error: no more observations ! \n",
      "cumulative reward:  629.3572486639023\n",
      "error: no more observations ! \n",
      "cumulative reward:  560.4146320223808\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.5314840376377106\n",
      "cumulative reward:  193.8664824962616\n",
      "error: no more observations ! \n",
      "Training step  44 \treward  96.66749922931194\n",
      "\n",
      "cumulative reward:  2.5485183596611023\n",
      "error: no more observations ! \n",
      "cumulative reward:  29.409540593624115\n",
      "error: no more observations ! \n",
      "cumulative reward:  27.209416776895523\n",
      "error: no more observations ! \n",
      "cumulative reward:  241.80374270677567\n",
      "error: no more observations ! \n",
      "cumulative reward:  394.7035033106804\n",
      "cumulative reward:  392.8761707544327\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.340955346822739\n",
      "error: no more observations ! \n",
      "cumulative reward:  741.2279547452927\n",
      "error: no more observations ! \n",
      "cumulative reward:  48.27314281463623\n",
      "error: no more observations ! \n",
      "cumulative reward:  69.40318024158478\n",
      "Training step  45 \treward  58.838161528110504\n",
      "\n",
      "cumulative reward:  1.7615601122379303\n",
      "cumulative reward:  2.4030489325523376\n",
      "error: no more observations ! \n",
      "cumulative reward:  62.26091614365578\n",
      "error: no more observations ! \n",
      "cumulative reward:  97.17774212360382\n",
      "error: no more observations ! \n",
      "cumulative reward:  71.52181974053383\n",
      "error: no more observations ! \n",
      "cumulative reward:  78.32228788733482\n",
      "error: no more observations ! \n",
      "cumulative reward:  62.64064979553223\n",
      "error: no more observations ! \n",
      "cumulative reward:  85.47598958015442\n",
      "error: no more observations ! \n",
      "cumulative reward:  51.989031076431274\n",
      "error: no more observations ! \n",
      "cumulative reward:  28.770563691854477\n",
      "error: no more observations ! \n",
      "cumulative reward:  28.344658613204956\n",
      "error: no more observations ! \n",
      "Training step  46 \treward  28.557611152529716\n",
      "\n",
      "cumulative reward:  71.73653829097748\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.689214885234833\n",
      "error: no more observations ! \n",
      "cumulative reward:  47.98711201548576\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.783305317163467\n",
      "cumulative reward:  80.85345754027367\n",
      "error: no more observations ! \n",
      "cumulative reward:  39.462984800338745\n",
      "error: no more observations ! \n",
      "cumulative reward:  744.9120036363602\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.64909002184868\n",
      "error: no more observations ! \n",
      "cumulative reward:  21.67130810022354\n",
      "Training step  47 \treward  45.16019906103611\n",
      "\n",
      "cumulative reward:  60.51764318346977\n",
      "error: no more observations ! \n",
      "cumulative reward:  56.58296525478363\n",
      "error: no more observations ! \n",
      "cumulative reward:  45.89448004961014\n",
      "cumulative reward:  54.42753076553345\n",
      "cumulative reward:  74.85840240120888\n",
      "error: no more observations ! \n",
      "cumulative reward:  84.53096401691437\n",
      "error: no more observations ! \n",
      "cumulative reward:  52.455216109752655\n",
      "cumulative reward:  18.153233647346497\n",
      "error: no more observations ! \n",
      "cumulative reward:  63.165936797857285\n",
      "cumulative reward:  47.46728527545929\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.401903003454208\n",
      "error: no more observations ! \n",
      "cumulative reward:  51.96582591533661\n",
      "error: no more observations ! \n",
      "Training step  48 \treward  28.68386445939541\n",
      "\n",
      "cumulative reward:  51.29564082622528\n",
      "cumulative reward:  70.39193153381348\n",
      "error: no more observations ! \n",
      "cumulative reward:  81.17148408293724\n",
      "error: no more observations ! \n",
      "cumulative reward:  52.88764750957489\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.0603630244731903\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.2245033979415894\n",
      "error: no more observations ! \n",
      "cumulative reward:  4.15916383266449\n",
      "error: no more observations ! \n",
      "cumulative reward:  46.000092923641205\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.449404686689377\n",
      "error: no more observations ! \n",
      "cumulative reward:  23.55270552635193\n",
      "cumulative reward:  12.942526370286942\n",
      "error: no more observations ! \n",
      "cumulative reward:  746.2525850534439\n",
      "error: no more observations ! \n",
      "Training step  49 \treward  379.5975557118654\n",
      "\n",
      "cumulative reward:  16.891524702310562\n",
      "error: no more observations ! \n",
      "cumulative reward:  742.8286703824997\n",
      "error: no more observations ! \n",
      "cumulative reward:  746.7117552757263\n",
      "error: no more observations ! \n",
      "cumulative reward:  745.6484254002571\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.576686531305313\n",
      "error: no more observations ! \n",
      "cumulative reward:  747.4745395183563\n",
      "error: no more observations ! \n",
      "Training step  50 \treward  747.4745395183563\n",
      "\n",
      "cumulative reward:  46.19937151670456\n",
      "error: no more observations ! \n",
      "cumulative reward:  28.734593152999878\n",
      "error: no more observations ! \n",
      "cumulative reward:  104.48986926674843\n",
      "cumulative reward:  750.0618044734001\n",
      "error: no more observations ! \n",
      "cumulative reward:  746.3862180113792\n",
      "error: no more observations ! \n",
      "cumulative reward:  747.6012684106827\n",
      "error: no more observations ! \n",
      "cumulative reward:  747.9783704280853\n",
      "error: no more observations ! \n",
      "cumulative reward:  24.350242793560028\n",
      "cumulative reward:  36.30882388353348\n",
      "error: no more observations ! \n",
      "cumulative reward:  744.9175884723663\n",
      "error: no more observations ! \n",
      "Training step  51 \treward  268.52555171648663\n",
      "\n",
      "cumulative reward:  747.7431849837303\n",
      "cumulative reward:  747.3601275682449\n",
      "error: no more observations ! \n",
      "cumulative reward:  739.5124081969261\n",
      "error: no more observations ! \n",
      "cumulative reward:  21.087061911821365\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.4378868639469147\n",
      "cumulative reward:  14.482153713703156\n",
      "error: no more observations ! \n",
      "Training step  52 \treward  12.335700829823812\n",
      "\n",
      "cumulative reward:  2.0116688311100006\n",
      "cumulative reward:  8.965967178344727\n",
      "cumulative reward:  12.75749272108078\n",
      "error: no more observations ! \n",
      "cumulative reward:  4.686751157045364\n",
      "error: no more observations ! \n",
      "cumulative reward:  33.56675925850868\n",
      "error: no more observations ! \n",
      "cumulative reward:  19.63404083251953\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.5294628739356995\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  13.654878973960876\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  3.884454995393753\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  1.5930647552013397\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  16.41046017408371\n",
      "cumulative reward:  15.601455807685852\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.36512315273285\n",
      "error: no more observations ! \n",
      "Training step  53 \treward  14.459013044834137\n",
      "\n",
      "cumulative reward:  11.13670164346695\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.703337490558624\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.710317850112915\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.719882071018219\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.347810447216034\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.293367236852646\n",
      "cumulative reward:  17.294017493724823\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.624655961990356\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.6576294004917145\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.512228399515152\n",
      "cumulative reward:  7.307097315788269\n",
      "error: no more observations ! \n",
      "cumulative reward:  68.50259974598885\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.5277514457702637\n",
      "error: no more observations ! \n",
      "cumulative reward:  30.03215304017067\n",
      "error: no more observations ! \n",
      "cumulative reward:  70.30731654167175\n",
      "error: no more observations ! \n",
      "cumulative reward:  40.04174095392227\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.889527767896652\n",
      "error: no more observations ! \n",
      "cumulative reward:  57.47714379429817\n",
      "cumulative reward:  12.618285059928894\n",
      "error: no more observations ! \n",
      "cumulative reward:  17.922564327716827\n",
      "cumulative reward:  6.14137801527977\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.363297909498215\n",
      "error: no more observations ! \n",
      "Training step  54 \treward  11.809080084164938\n",
      "\n",
      "cumulative reward:  6.728477984666824\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.8439757227897644\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.703383535146713\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.300811052322388\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.587278097867966\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.026161909103394\n",
      "cumulative reward:  7.182032495737076\n",
      "error: no more observations ! \n",
      "cumulative reward:  30.969311624765396\n",
      "error: no more observations ! \n",
      "cumulative reward:  33.25905644893646\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.7610624730587\n",
      "cumulative reward:  24.702826648950577\n",
      "error: no more observations ! \n",
      "cumulative reward:  54.99343663454056\n",
      "cumulative reward:  35.0614076256752\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.528381645679474\n",
      "error: no more observations ! \n",
      "cumulative reward:  15.018749713897705\n",
      "error: no more observations ! \n",
      "cumulative reward:  48.73436766862869\n",
      "error: no more observations ! \n",
      "cumulative reward:  31.642237603664398\n",
      "error: no more observations ! \n",
      "cumulative reward:  62.57725718617439\n",
      "cumulative reward:  4.562575548887253\n",
      "cumulative reward:  7.660370647907257\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.860747307538986\n",
      "error: no more observations ! \n",
      "Training step  55 \treward  6.361231168111165\n",
      "\n",
      "cumulative reward:  10.887732565402985\n",
      "cumulative reward:  11.460848450660706\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.994141101837158\n",
      "cumulative reward:  14.72822117805481\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.020038932561874\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.262892365455627\n",
      "cumulative reward:  28.22788655757904\n",
      "cumulative reward:  15.318622648715973\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.182601064443588\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.652559757232666\n",
      "cumulative reward:  37.640113681554794\n",
      "error: no more observations ! \n",
      "cumulative reward:  19.8300821185112\n",
      "cumulative reward:  47.60264325141907\n",
      "cumulative reward:  20.010578364133835\n",
      "error: no more observations ! \n",
      "cumulative reward:  44.42646414041519\n",
      "error: no more observations ! \n",
      "cumulative reward:  22.394303619861603\n",
      "error: no more observations ! \n",
      "cumulative reward:  43.10285925865173\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.531069964170456\n",
      "error: no more observations ! \n",
      "cumulative reward:  4.250184208154678\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.483222424983978\n",
      "error: no more observations ! \n",
      "Training step  56 \treward  6.088158865769704\n",
      "\n",
      "cumulative reward:  9.464178085327148\n",
      "cumulative reward:  15.294934034347534\n",
      "cumulative reward:  9.63178265094757\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.46411195397377\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.130167931318283\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.769308686256409\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.140082001686096\n",
      "error: no more observations ! \n",
      "cumulative reward:  15.606878757476807\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.775224089622498\n",
      "error: no more observations ! \n",
      "cumulative reward:  50.942671090364456\n",
      "cumulative reward:  10.088386118412018\n",
      "error: no more observations ! \n",
      "cumulative reward:  15.888290137052536\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.58600801229477\n",
      "cumulative reward:  4.3332445323467255\n",
      "cumulative reward:  22.00604224205017\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.788102000951767\n",
      "cumulative reward:  33.52213501930237\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.184603333473206\n",
      "error: no more observations ! \n",
      "cumulative reward:  23.506407737731934\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.647499322891235\n",
      "error: no more observations ! \n",
      "cumulative reward:  51.48542404174805\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.00170561671257\n",
      "error: no more observations ! \n",
      "cumulative reward:  4.257609248161316\n",
      "cumulative reward:  14.727550059556961\n",
      "error: no more observations ! \n",
      "Training step  57 \treward  10.99562164147695\n",
      "\n",
      "cumulative reward:  9.708673268556595\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.11445540189743\n",
      "error: no more observations ! \n",
      "cumulative reward:  17.03432661294937\n",
      "cumulative reward:  14.381876826286316\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.243872612714767\n",
      "error: no more observations ! \n",
      "cumulative reward:  4.590330570936203\n",
      "error: no more observations ! \n",
      "cumulative reward:  23.217311441898346\n",
      "cumulative reward:  27.98474371433258\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.090220957994461\n",
      "error: no more observations ! \n",
      "cumulative reward:  21.21684902906418\n",
      "error: no more observations ! \n",
      "cumulative reward:  20.982714921236038\n",
      "cumulative reward:  15.367424607276917\n",
      "error: no more observations ! \n",
      "cumulative reward:  36.51729017496109\n",
      "cumulative reward:  55.810014843940735\n",
      "error: no more observations ! \n",
      "cumulative reward:  49.084315687417984\n",
      "error: no more observations ! \n",
      "cumulative reward:  34.53477093577385\n",
      "error: no more observations ! \n",
      "cumulative reward:  38.63567328453064\n",
      "cumulative reward:  36.22887808084488\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.024517178535461\n",
      "error: no more observations ! \n",
      "cumulative reward:  12.767843961715698\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.46772775053978\n",
      "error: no more observations ! \n",
      "Training step  58 \treward  10.75336296359698\n",
      "\n",
      "cumulative reward:  6.312771916389465\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.118453204631805\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.212898701429367\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.787938714027405\n",
      "cumulative reward:  3.750412344932556\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.392368644475937\n",
      "cumulative reward:  11.437931954860687\n",
      "error: no more observations ! \n",
      "cumulative reward:  4.841425657272339\n",
      "error: no more observations ! \n",
      "cumulative reward:  41.768539786338806\n",
      "error: no more observations ! \n",
      "cumulative reward:  37.65652546286583\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.00754424929619\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.667704463005066\n",
      "cumulative reward:  13.182379931211472\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.27362060546875\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.14729768037796\n",
      "error: no more observations ! \n",
      "cumulative reward:  29.89294809103012\n",
      "cumulative reward:  30.99868881702423\n",
      "cumulative reward:  9.617012321949005\n",
      "error: no more observations ! \n",
      "cumulative reward:  26.046825885772705\n",
      "error: no more observations ! \n",
      "cumulative reward:  14.636354327201843\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.145126402378082\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.925512492656708\n",
      "error: no more observations ! \n",
      "Training step  59 \treward  14.23566440741221\n",
      "\n",
      "cumulative reward:  4.58284729719162\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.6886394917964935\n",
      "error: no more observations ! \n",
      "cumulative reward:  13.714768558740616\n",
      "error: no more observations ! \n",
      "cumulative reward:  35.30095624923706\n",
      "error: no more observations ! \n",
      "cumulative reward:  8.302917182445526\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.743301689624786\n",
      "error: no more observations ! \n",
      "cumulative reward:  42.37508314847946\n",
      "error: no more observations ! \n",
      "cumulative reward:  18.116414576768875\n",
      "error: no more observations ! \n",
      "cumulative reward:  55.32340228557587\n",
      "error: no more observations ! \n",
      "cumulative reward:  108.70148777961731\n",
      "cumulative reward:  12.578346580266953\n",
      "error: no more observations ! \n",
      "cumulative reward:  102.47167021036148\n",
      "cumulative reward:  21.570411324501038\n",
      "error: no more observations ! \n",
      "cumulative reward:  4.914755761623383\n",
      "cumulative reward:  5.66739296913147\n",
      "cumulative reward:  63.986247181892395\n",
      "error: no more observations ! \n",
      "cumulative reward:  70.67815381288528\n",
      "error: no more observations ! \n",
      "Training step  60 \treward  70.67815381288528\n",
      "\n",
      "cumulative reward:  13.142767488956451\n",
      "error: no more observations ! \n",
      "cumulative reward:  9.457424968481064\n",
      "cumulative reward:  29.151217818260193\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.334909588098526\n",
      "error: no more observations ! \n",
      "cumulative reward:  17.79284319281578\n",
      "cumulative reward:  43.342301189899445\n",
      "cumulative reward:  35.30754631757736\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.581600040197372\n",
      "cumulative reward:  42.02576154470444\n",
      "error: no more observations ! \n",
      "cumulative reward:  199.7560961842537\n",
      "error: no more observations ! \n",
      "cumulative reward:  55.07135075330734\n",
      "error: no more observations ! \n",
      "cumulative reward:  61.581520944833755\n",
      "Training step  61 \treward  61.581520944833755\n",
      "\n",
      "cumulative reward:  194.1960169672966\n",
      "error: no more observations ! \n",
      "cumulative reward:  692.5853886008263\n",
      "error: no more observations ! \n",
      "cumulative reward:  706.653601527214\n",
      "cumulative reward:  662.3111830353737\n",
      "error: no more observations ! \n",
      "cumulative reward:  736.4407378435135\n",
      "cumulative reward:  2.8621457517147064\n",
      "cumulative reward:  1.625858873128891\n",
      "cumulative reward:  1.7308813035488129\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "Training step  62 \treward  1.3047214820981026\n",
      "\n",
      "cumulative reward:  0.20199593901634216\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  113.20176392793655\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  744.351160466671\n",
      "error: no more observations ! \n",
      "Training step  63 \treward  744.351160466671\n",
      "\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  746.3024681806564\n",
      "error: no more observations ! \n",
      "cumulative reward:  746.0424383878708\n",
      "error: no more observations ! \n",
      "cumulative reward:  741.8543009757996\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  198.5303089618683\n",
      "cumulative reward:  467.49689212441444\n",
      "cumulative reward:  397.6536073088646\n",
      "cumulative reward:  396.4048126935959\n",
      "cumulative reward:  199.7481827735901\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  196.716726064682\n",
      "cumulative reward:  197.13223218917847\n",
      "cumulative reward:  199.2446769475937\n",
      "cumulative reward:  552.2788314819336\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  198.52562749385834\n",
      "cumulative reward:  515.8719555735588\n",
      "cumulative reward:  568.3279713988304\n",
      "cumulative reward:  195.65139937400818\n",
      "cumulative reward:  712.701607644558\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  208.93144488334656\n",
      "cumulative reward:  568.745597243309\n",
      "cumulative reward:  198.67217826843262\n",
      "cumulative reward:  198.04886013269424\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  199.74596238136292\n",
      "cumulative reward:  396.32710802555084\n",
      "cumulative reward:  198.2670413851738\n",
      "cumulative reward:  199.63773345947266\n",
      "cumulative reward:  199.75425815582275\n",
      "cumulative reward:  474.03947019577026\n",
      "cumulative reward:  519.531256198883\n",
      "cumulative reward:  485.4566682577133\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  398.36275190114975\n",
      "cumulative reward:  202.4172089099884\n",
      "cumulative reward:  196.97812938690186\n",
      "cumulative reward:  196.77288991212845\n",
      "cumulative reward:  471.48359590768814\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  198.56097888946533\n",
      "cumulative reward:  538.6066747903824\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  396.7192553281784\n",
      "cumulative reward:  199.5943307876587\n",
      "cumulative reward:  198.21934068202972\n",
      "Training step  64 \treward  263.1368348247475\n",
      "\n",
      "cumulative reward:  199.64595317840576\n",
      "cumulative reward:  580.126119017601\n",
      "cumulative reward:  406.8562339544296\n",
      "cumulative reward:  197.7708420753479\n",
      "cumulative reward:  199.92176628112793\n",
      "cumulative reward:  198.66627860069275\n",
      "cumulative reward:  195.06392991542816\n",
      "cumulative reward:  197.9244041442871\n",
      "cumulative reward:  697.0141468644142\n",
      "cumulative reward:  395.2221168875694\n",
      "cumulative reward:  199.90952253341675\n",
      "cumulative reward:  559.484337747097\n",
      "cumulative reward:  199.68132066726685\n",
      "cumulative reward:  526.7955422997475\n",
      "cumulative reward:  396.1618049144745\n",
      "cumulative reward:  198.01115608215332\n",
      "cumulative reward:  395.2016897201538\n",
      "cumulative reward:  501.7399262189865\n",
      "cumulative reward:  450.6710329055786\n",
      "cumulative reward:  199.6463475227356\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  396.85073041915894\n",
      "cumulative reward:  196.9655470252037\n",
      "cumulative reward:  199.73381423950195\n",
      "cumulative reward:  198.11507266759872\n",
      "cumulative reward:  398.28112655878067\n",
      "cumulative reward:  198.35728693008423\n",
      "cumulative reward:  562.335359275341\n",
      "cumulative reward:  396.3316979408264\n",
      "cumulative reward:  398.13791435956955\n",
      "cumulative reward:  594.2817370891571\n",
      "cumulative reward:  198.08670246601105\n",
      "cumulative reward:  198.34411346912384\n",
      "cumulative reward:  473.83078396320343\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  198.43930566310883\n",
      "cumulative reward:  190.69480240345\n",
      "cumulative reward:  197.5440058708191\n",
      "cumulative reward:  198.2905716896057\n",
      "cumulative reward:  655.5628185272217\n",
      "cumulative reward:  196.84002304077148\n",
      "cumulative reward:  566.4637179970741\n",
      "cumulative reward:  199.698548913002\n",
      "cumulative reward:  397.9568023085594\n",
      "cumulative reward:  452.9812914133072\n",
      "cumulative reward:  1.666854351758957\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.1304321587085724\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.5873852670192719\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.4613603949546814\n",
      "Training step  65 \treward  1.1678154096007347\n",
      "\n",
      "cumulative reward:  -0.5978678166866302\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.19861829280853271\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.409247100353241\n",
      "error: no more observations ! \n",
      "cumulative reward:  -0.2062128484249115\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.1519576013088226\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.06632259488105774\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.251308411359787\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.1809370815753937\n",
      "cumulative reward:  1.4098214209079742\n",
      "cumulative reward:  2.322762131690979\n",
      "cumulative reward:  0.8002869188785553\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.09835287928581238\n",
      "cumulative reward:  3.9208429753780365\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.1839458644390106\n",
      "error: no more observations ! \n",
      "cumulative reward:  2.4200463593006134\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.023634731769561768\n",
      "cumulative reward:  1.195585310459137\n",
      "error: no more observations ! \n",
      "cumulative reward:  0.920844554901123\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  1.1126496195793152\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  66 \treward  -1.0\n",
      "\n",
      "cumulative reward:  26.81571716070175\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "Training step  67 \treward  -1.0\n",
      "\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  4.552220493555069\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  2.0858658254146576\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.010651588439941406\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.0\n",
      "cumulative reward:  0.5310925245285034\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.1530233025550842\n",
      "cumulative reward:  0.11343768239021301\n",
      "error: no more observations ! \n",
      "Training step  68 \treward  1.2658511698246002\n",
      "\n",
      "cumulative reward:  2.8345974385738373\n",
      "cumulative reward:  4.219481557607651\n",
      "cumulative reward:  4.581503480672836\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.9358586966991425\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.342344343662262\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.3110450208187103\n",
      "cumulative reward:  14.130868524312973\n",
      "cumulative reward:  13.105063557624817\n",
      "cumulative reward:  3.1097267866134644\n",
      "error: no more observations ! \n",
      "cumulative reward:  3.8868954479694366\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  56.14039993286133\n",
      "error: no more observations ! \n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "cumulative reward:  -1.0\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.116073161363602\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.061179339885712\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.053974896669388\n",
      "error: no more observations ! \n",
      "cumulative reward:  26.056361854076385\n",
      "Training step  69 \treward  13.321897312998772\n",
      "\n",
      "cumulative reward:  11.597604542970657\n",
      "cumulative reward:  3.096527248620987\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.358989179134369\n",
      "cumulative reward:  27.85545802116394\n",
      "error: no more observations ! \n",
      "cumulative reward:  29.62402194738388\n",
      "error: no more observations ! \n",
      "cumulative reward:  30.023276209831238\n",
      "error: no more observations ! \n",
      "cumulative reward:  11.95819491147995\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.610565572977066\n",
      "cumulative reward:  21.426697909832\n",
      "cumulative reward:  32.611905455589294\n",
      "cumulative reward:  28.27952480316162\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.760870963335037\n",
      "cumulative reward:  7.5610776245594025\n",
      "error: no more observations ! \n",
      "cumulative reward:  30.342092394828796\n",
      "error: no more observations ! \n",
      "cumulative reward:  1.5273398756980896\n",
      "error: no more observations ! \n",
      "cumulative reward:  22.717274516820908\n",
      "error: no more observations ! \n",
      "cumulative reward:  7.360050797462463\n",
      "error: no more observations ! \n",
      "cumulative reward:  26.518747627735138\n",
      "error: no more observations ! \n",
      "cumulative reward:  16.83208203315735\n",
      "cumulative reward:  26.486099898815155\n",
      "cumulative reward:  3.2714769542217255\n",
      "error: no more observations ! \n",
      "cumulative reward:  10.653113842010498\n",
      "error: no more observations ! \n",
      "cumulative reward:  6.927557051181793\n",
      "cumulative reward:  7.019623667001724\n",
      "error: no more observations ! \n",
      "cumulative reward:  5.844970673322678\n",
      "cumulative reward:  6.054109960794449\n",
      "cumulative reward:  2.0762002170085907\n",
      "cumulative reward:  10.655913084745407\n",
      "cumulative reward:  18.36607414484024\n",
      "cumulative reward:  23.398496329784393\n",
      "error: no more observations ! \n",
      "Training step  70 \treward  17.473494519790012\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x134487390>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------\n",
    "# This code is used to close an env that might not have been closed before\n",
    "try:\n",
    "  env.close()\n",
    "except:\n",
    "  pass\n",
    "# -----------------\n",
    "\n",
    "from mlagents_envs.registry import default_registry\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create the GridWorld Environment from the registry\n",
    "env = UE(file_name='run32_train', seed=1, worker_id=1, side_channels=[])\n",
    "# env = default_registry[\"GridWorld\"].make()\n",
    "print(\"GridWorld environment created.\")\n",
    "\n",
    "# moved Qnet outside to reuse it\n",
    "\n",
    "# Create a new Q-Network. \n",
    "# qnet = VisualQNetwork((44, 1), 126, 3)\n",
    "\n",
    "experiences: Buffer = []\n",
    "optim = torch.optim.Adam(qnet.parameters(), lr= 0.001)\n",
    "\n",
    "cumulative_rewards: List[float] = []\n",
    "\n",
    "# The number of training steps that will be performed\n",
    "NUM_TRAINING_STEPS = 10000000 #70\n",
    "# The number of experiences to collect per training step\n",
    "NUM_NEW_EXP = 1000\n",
    "# The maximum size of the Buffer\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "for n in range(NUM_TRAINING_STEPS):\n",
    "  new_exp,_ = Trainer.generate_trajectories(env, qnet, NUM_NEW_EXP, epsilon=0.1)\n",
    "  random.shuffle(experiences)\n",
    "  if len(experiences) > BUFFER_SIZE:\n",
    "    experiences = experiences[:BUFFER_SIZE]\n",
    "  experiences.extend(new_exp)\n",
    "  Trainer.update_q_net(qnet, optim, experiences, 3)\n",
    "  _, rewards = Trainer.generate_trajectories(env, qnet, 100, epsilon=0)\n",
    "  cumulative_rewards.append(rewards)\n",
    "  print(\"Training step \", n+1, \"\\treward \", rewards)\n",
    "  print()\n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Show the training graph\n",
    "plt.plot(range(NUM_TRAINING_STEPS), cumulative_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed environment\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "print(\"Closed environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.2-cp37-cp37m-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 743 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-macosx_10_9_x86_64.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 441 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/ribr/.virtualenvs/ultron/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
